{"pages":[{"title":"About","date":"2016-10-24T02:24:00.000Z","path":"about/index.html","text":""},{"title":"Tags","date":"2018-10-11T04:38:53.591Z","path":"tags/index.html","text":""},{"title":"Categories","date":"2018-10-11T04:38:40.994Z","path":"categories/index.html","text":""}],"posts":[{"title":"","date":"2019-03-31T01:53:20.667Z","path":"wiki/Java/笔记/","text":"Java搜索技巧末尾加上PDF，可以搜出一些高质量的文章，包括一些技术分享、大学的课件。 Wikipedia看参考文献，会有很多不错的资料。 关键字：Overview，Demystify 学习过程：从宏观上了解 基础StringString.intern()如果常量池中存在当前字符串, 就会直接返回当前字符串. 如果常量池中没有此字符串, 会将此字符串放入常量池中后, 再返回。常量池是堆中的一块特殊区域。 hashCode()和equals()hashcode规约 对同一对象，hashcode方法返回值每次应相同 如果不同，则会导致根据hashcode变化无法在桶中找到该元素。Python字典中要求key需要是immutable的也是这个原因 如果重写了equals()方法，检查条件“两个对象使用equals()方法判断为相等，则hashCode()方法也应该相等”是否成立，如果不成立，则重写hashCode ()方法。 不要求不同对象返回不同hashcode，但是如果每个对象都可以返回不同的hashcode，可以提高hash table的性能。 重写equals时为什么要重写hashcode不重写hashcode方法，涉及到HashMap、HashSet等依赖对象hashcode值的集合会出问题。 HashMap通过hashcode将对象放到对应的桶结构中，在取数据时，根据hashcode定位到桶，然后根据equal在桶中寻找到对象。 如果不重写hashcode，就可能出现两个相同的对象(业务上)，由于hashcode不同，而会在HashMap中存两份。 synchronized关键字原理synchronized通过monitor来实现线程同步，而monitor是通过mutex lock和condition variable来实现互斥，每个Java对象(包括类对象)都有个mutex lock。在synchronized包裹的代码前后会有monitorenter和moniterexit指令。Monitor中的互斥锁是OS层面来支持，在获取(monitor entry)和释放锁(monitor exit)存在大量的开销。因此HotSpot VM在这方面做了些优化，引入了轻量级锁和偏向锁等。 monitor监视器是一个可以实现线程互斥和协作的结构。 监视器可以看作一个房子，这个房子有个只能被一个线程占有的特殊的房间，房间里保护的就是临界资源。 如果一个线程需要进入特殊房间，首选需要在大门(Entry Set)中等待，由调度策略决定下一个进入房间的是哪个线程。如果线程由于某种原因被挂起，则进入Wait Set，在合适的时间会被安排到特殊房间里。 进入房子 - entering the monitor 进入特殊房间 - acquiring the monitor 占据特殊房间 - owning the monitor 离开特殊房间 - releasing the monitor 离开房子 - exiting the monitor Synchornized关键字就是将其包裹的代码块放入特殊房间里，线程需要先enter the monitor后进入entry set，之后acquire the monitor才能运行代码块。 wait和notify也是利用monitor，原理是：当一个线程own the monitor时，可以调用wait方法来将自己挂起，release the monitor并进入到Wait Set中，直到其他在拥有monitor的线程调用notify方法。当线程调用notify时，并不是立马就release the monitor，只有当线程release the monitor后，等待线程才会去acquire the monitor，但是monitor也可能被其他线程获取到，因此即使wait线程获取到monitor，也需要检查下数据是否满足其想要的条件。 synchronized锁的优化Monitor中的互斥锁是OS层面来支持，在获取(monitor entry)和释放锁(monitor exit)时存在大量的开销。因此HotSpot VM在这方面做了些优化。 对象头对象头主要包含两部分数据：Mark Word、Klass Pointer(类型指针，用来确定是哪个类的实例)。 Mark Word：存储了对象的HashCode、分代年龄和锁标志位信息。对象的状态不同，Mark Word里存储的信息也会不同。 锁消除(Lock Elision)通过逃逸分析的技术，如果对象只会被一个线程使用，在编译成字节码的时候会去掉不必要的锁。 123456public String getFruits (String... fruits ) &#123; Vector v = new Vector(); for (String fruit: fruits) v.add(fruit); return v.toString();&#125; 这里v的引用不会逃出getFruits方法，因此Vector的synchronized锁可以去掉。 锁粗化(Lock Coarsening)如下 12345public Vector getFruits(Vector v) &#123; v.add(\"Banana\"); v.add(\"Melon\"); return v;&#125; 每调一次add方法都有一次获取锁、释放锁的过程，编译器会用一个锁将它们包起来，这个过程叫做锁粗化。对于循环，锁粗化会导致锁长时间被一个线程持有，因此锁粗化只会应用于非循环的情况。 自旋锁与自适应自旋锁阻塞或唤醒线程存在上下文切换的代价。因此出现了自旋锁，当发现自旋时间过长时，可以将其转化成重量级锁(即OS层面对锁)，因此称为自适应自旋锁。自旋锁的实现原理是CAS。 轻量级锁大多数时候，不存在锁的竞争。轻量级锁是根据这个场景进行优化。 拷贝对象头中的Mark Word到当前线程栈帧中的Lock Record CAS将Mark Word的ptr指向线程Lock Record 成功则获取到锁，失败则自旋再尝试，自旋达到一定次数后膨胀为重量级锁。 偏向锁大多数情况，锁总是被同一个线程获得，因此出现了偏向锁。 当锁对象第一次被线程获取时，虚拟机会将对象头中的标志位设为偏向模式，并通过CAS在Mark Word里存储当前线程ID，在线程进入或退出同步代码块时，不是去获取或释放锁，而是检测Mark Word里存储的线程ID是否与当前线程ID相同即可，因此相比自旋锁，偏向锁少了多处CAS的开销。如果相同，说明已经获取到锁，如果不同，说明偏向的是别的线程，这时候就应该撤销偏向锁，不能继续偏向原来的线程。偏向锁的撤销，需要在如下场景下： volatilevolatile作用在单核处理中，同一进程的不同线程访问共享数据时，CPU先将共享变量加载到共享缓存中，不同线程访问该数据时，都是访问的同一个地址，因此volatile的可见性就没有必要了。但是在多核处理器中，每个CPU都会从主存中将数据加载到其自身的缓存中，这时候就可能会出现缓存不一致的问题，当多线程运行在不同的CPU时，就可能导致每个线程看到的数据不一致，volatile就是为了解决这个问题。 volatile修饰的变量具有可见性，对一个volatile变量的写操作及这个写操作之前的所有操作Happens-Before对这个变量的读操作及这个读操作之后的所有操作。 volatile实现原理volatile需要借助硬件来实现。对volatile变量的写操作，会在正常汇编指令前加一个lock前缀的指令，这个指令在多核处理器会做两件事。 锁总线，其它CPU对内存的读写请求都会被阻塞，直到锁释放，由于锁总线期间其他CPU没法访问内存，因此其开销比较大，后来的处理器都采用锁缓存替代锁总线，通过缓存一致性协议来实现数据一致。缓存一致性协议有多种，常见的是通过嗅探来实现，通过不停的嗅探总线上的数据交换，从而当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。 lock后的写操作会回写已修改的数据，同时让其它CPU相关缓存行失效，从而重新从主存中加载最新的数据 ThreadLocal作用每个线程保存一个变量的副本。 应用场景 方便传参数，A方法到F方法，中间经过了很多方法，现在需要从A多传一个参数到F，为了避免对中间方法对应用，可以用threadlocal来进行传参。 其实应用场景就跟其作用所说一样，需要使用与线程相关的数据时使用。 原理已有的条件是什么？: ThreadLocal变量，线程实例 求解的问题: ThreadLocal实现原理 每个线程一个变量，通过ThreadLocal的方法获取到该值，很容易想到的就是Map。即线程实例为键，变量为值。那么这个map保存在哪呢？正常想到的想法是保存在ThreadLocal对象里，即ThreadLocal t 有个Map，这个Map保存了线程和其值的关系。但是线程对象大多数是临时对象，也就是说ThreaLocal的这个Map需要经常更新，不然就会保持对线程的引用，导致线程无法回收。既然线程的变量存活周期与线程是一样的，那么何不把这个变量保存在线程对象中呢，由于线程会有不同类型的threadlocal局部变量，因此需要一个字段能够包含这所有的threalocal，做法还是用map，key是ThreadLocal变量，而value是线程真正对应的值。Entry(ThreadLocal&lt;?&gt; k, Object v) JVMJVM内存区域类加载机制GCGC要做的三件事： 哪些内存需要回收(what) 什么时候回收(when) 怎么回收(how) 哪些内存需要回收可达性分析，GC Roots Tracing：当对象与GC Roots没有引用链相连时，该对象为不可达对象。GC Roots包括如下 System Class ​ 由bootstrap/system 类加载器加载的类 Native Code ​ Native code中的局部变量和全局变量 Thread Block ​ 当前活跃线程里引用的对象 Thread ​ 已启动的线程 Stack Local Java方法的local变量或参数 当一个对象被标记为不可达后，下一个垃圾回收会试图回收该对象，如果对象重写了finalize方法，并且在这个方法自救成功(将自身赋予某个引用)，则不会被回收，但是如果没有重写finalize或者已经执行过该方法，则自救失败。 什么时候回收要与怎么回收一起来看，Java主要采用了分代回收，将堆内存分成了新生代和老年代。 怎么回收通过垃圾收集器进行垃圾回收 垃圾回收分为三步： 标记(Mark) 要进行垃圾回收，首先要确定哪些是垃圾嘛，这一步将对对象进行扫描，来确定哪些对象需要回收 清除 既然知道哪些对象要回收，那么这一步就从内存中删掉这些对象 整理(compact) 如上所示，在清除时会产生内存碎片，可以在清除后进行整理，来清除内存碎片。 在上述步骤中，标记和整理是比较耗时的，随着对象越来越多，垃圾回收的时间也就越长，而实际上，一个应用的大多数对象其实存活时间是很短的，分代回收的思想是不同代的对象存活时间不一样，因此垃圾回收的频率应该也不一样，尽量做到：当开始垃圾回收时，能做到大多数对象被标记为可被回收，使得标记阶段做的活不是白费的。这就是为什么采用分代回收。 如图所示 大多数对象最初都被分配到新生代，对新生代里的对象的预期就是存活时间不长，当新生代区域满时，就会发生minor gc，当对象在新生代中存活超过一定的gc次数，就会被移动到老年代中，当老年代也需要回收时，此时会发生full gc。 GC流程如下： 对象首先放到eden区，eden区满时，发生minor gc，存活对象移动到S0，清除eden区。同时，对象被标记存活年龄。 下一次minor gc时，存活对象和S0的对象移动到S1，清除eden和S0区。 下一次，存活对象则从S1到S0，如此反复，当对象存活超过一定次数，移动到老年代。 ​ 为什么设置S0、S1？首先，为什么需要survivor区？如果没有survivor区，eden区满了之后就会被送到老年代，这会导致很快发生Full GC。这些对象可能还是属于死得早的对象，只不过逃过了第一次垃圾回收，设置S区作为缓冲区可以使得这些年轻对象仍在年轻代被回收。为什么需要两个S区？主要是为了避免内存碎片，如果只有一个，那么在第二次minor gc时，可能eden和survivor区都会有部分对象存活，如果把eden区存活对象放到s区，很明显会产生内存碎片。为了避免内存碎片，新增一个s区，将所有存活对象移动到另一个空的s区中去。 ​ Full GC具体什么时候发生？前面说到当老年代需要回收时，会触发Full GC。那么什么时候会触发呢，1. 当老年代空间不足时，空间不足包括几种可能：创建大对象、大数组，老年代没有足够大的连续空间时；新生代转入导致空间不足。2.Metaspace空间不足。3.System.gc()方法的调用，这个方法是建议虚拟机进行Full GC，很多时候确实也会导致Full GC。 ​ 存活的对象Survivor区放不下怎么办？如果Survivor区太小，放不下的对象会被直接放到老年代，如果Survivor区太大，则会造成无用的浪费。虚拟机会在每次垃圾回收时设置一个threshold，对象被晋升到老年代时的存活次数，这个值保证survivor区的剩余空间大概在一半左右。 垃圾回收算法对年轻代和老年代，可以采用不同的垃圾回收算法。 Serial GC单线程进行垃圾回收，没有线程间通信开销，效率比较高，适用于单处理器的机器。 也适用于一台机器上运行多个JVM(超过处理器数量)的情况，可以避免多线程回收对其他JVM的影响。还适用于对停顿时间要求不是很高的场景。 Parallel GC并行执行年轻代的垃圾回收，适用于对系统吞吐量要求较高的环境。 Concurrent GC减少应用的停顿时间。 应用可以对年轻代和老年代配置一组相互兼容的垃圾收集器。如下图所示。 stop-the-world pause: 只使应用线程全部暂停的垃圾回收。 所有的垃圾回收在minor gc时都会有stop-the-world pause，但是在full gc时，CMS和G1收集器与其他垃圾收集器的区别在于它们可以在标记阶段做到没有停顿，不过代价是占用更多的CPU资源。 CMS收集器CMS收集器使用一个或多个线程在后台定期对老年代进行回收。但是由于不进行整理操作，会产生内存碎片。 G1收集器G1收集器将堆分为了许多region。 堆大小什么时候扩容 MetaSpace大小设置过大导致发生Full GC 并发线程池的作用 线程的创建和销毁消耗资源，因此通过池技术来达到复用。 对线程进行管控，线程创建无限制的话，对整个系统可能造成致命影响。 根据业务创建线程池，可以对业务进行隔离，避免相互影响。 Java线程池1ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 重要参数 corePoolSize 池中的线程基本个数 maximumPoolSize 最大线程个数 keepAliveTime 当线程个数大于corePoolSize时，线程空闲时的最大存活时间 workQueue 存放任务的阻塞队列 handler 当队列和最大线程池都满了之后的饱和策略。 通过threadPool.execute(**new** Job())提交一个任务后，经历如下几个步骤 线程池提供了四种拒绝策略，也可以自己实现接口自定义饱和策略： 1、AbortPolicy：直接抛出异常，默认策略；2、CallerRunsPolicy：用调用者所在的线程来执行任务；3、DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；4、DiscardPolicy：直接丢弃任务； 线程池配置的合理性主要还是需要通过测试验证来确定。基本原则是：线程等待时间所占比例越高，需要越多线程；线程cpu时间所占比例越高，需要越少线程。 Thread.run()和Thread.start()区别run方法就是个普通方法，可以被重复调用，不能起到多线程的目的；调用start方法，会启动新的线程，线程获取到时间片后，会运行run方法，start不能被重复调用，为什么呢？如果在一个Thread对象执行多次并发操作，那么getStackTrace() and getState()应该返回什么？ 创建线程有哪几种方式 实现Runnable接口，重写run方法 继承Thread，重写run方法，Thread实现了Runnable接口，与方法1其实原理一样 实现Callable接口，结合FutureTask使用 数据结构解决哈希冲突的方法常用方法有开放地址法(Python 字典实现)、拉链法(Java HashMap实现)。参考 操作系统进程和线程的区别进程是一个资源的容器，为进程里的所有线程提供共享资源，进程是系统资源分配的单位，线程是系统调度的单位。 线程有自己独立的程序计数器和栈，一个进程内的线程共享地址空间，创建和销毁线程的开销比进程小。线程依赖于进程而存在。 进程间通信比线程间通信要复杂。 多线程和多进程如何选择多进程的系统鲁棒性更好，适合于分布式场景，内存地址空间隔离，对于不需要共享数据的情况下，可以使用多进程。 线程创建和销毁的开销小，对于一些服务器响应任务，所需线程数量经常变化的场景适合用多线程，而不适合用多进程。线程间可以共享内存地址空间，这也是需要多线程的原因。 强相关的处理用线程，弱相关的处理用进程。多线程更方便于功能的内聚，更有力的进行资源的共享，多进程更方便于功能的可拆分，但多进程会导致资源共享的困难。需要多任务进行大量CPU计算的适合用多线程，因为线程切换比较快。 可能要扩展到多机分布的用进程，实际应用中都是进程+线程的结合方式 数据库四种隔离级别读未提交读不会加锁，其他事务在写的时候会加排它锁(排它锁会阻止其它事务再对其锁定的数据加读或写的锁，但是对不加锁的读无影响)。 读已提交MVCC机制实现，MVCC版本的生成时机是每次select时，因此会出现不可重复读现象。 可重复读隔离级别的底层实现MVCC机制，一次事务中，只在第一次select时生成版本，后续的查询都是在这个版本上进行，从而实现了可重复读。但是因为MVCC的快照只对读操作有效，对写操作无效，举例说明会更清晰一点： 事务A依次执行如下3条sql，事务B在语句1和2之间，插入10条age=20的记录，事务A就幻读了。 1234561. select count(1) from user where age=20;-- return 0: 当前没有age=20的2. update user set name=test where age=20;-- Affects 10 rows: 因为事务B刚写入10条age=20的记录，而写操作是不受MVCC影响，能看到最新数据的，所以更新成功，而一旦操作成功，这些被操作的数据就会对当前事务可见3. select count(1) from user where age=20;-- return 10: 出现幻读 REPEATABLE READ级别，可以防止大部分的幻读，但像前边举例读-写-读的情况，使用不加锁的select依然会幻读。 Serializable读加共享锁，写加排他锁，读写互斥。 为什么索引快 索引块的数量比数据块数量少 键被排序，可以使用查找算法高效查找 索引文件可能足够小，以至于可以永久存放在主存缓冲区中 哪些情况下不会使用索引 全表扫描比使用索引快，不会使用索引 like是以%开头 潜在的数据类型转换 索引列参与了函数运算 or关键字，其中一个字段没索引 B+树和B树的区别B树是充分利用磁盘预读功能而创建的一种数据结构，B树的每个节点可以存储多个关键字，它将节点大小设置为磁盘页的大小，充分利用了磁盘预读的功能。每次读取磁盘页时就会读取一整个节点。也正因每个节点存储着非常多个关键字，树的深度就会非常的小。进而要执行的磁盘读取操作次数就会非常少，更多的是在内存中对读取进来的数据进行查找。 B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点大小比B树小，同一磁盘块所能容纳的关键字数量也更多，一次能读入内存中的关键字也就越多，IO读写次数也就降低了。 B+树基于范围的查询更简洁，因为叶子节点有指向下一个叶子节点的指针。 B+树的查询效率更加稳定。任何关键字的查找必须走一条从根结点到叶子结点的路。 CBOCBO会从目标sql诸多可能的执行路径中选择一条成本值(消耗的I/O和CPU资源)最小的执行路径来作为其执行计划。 cbo的缺陷cbo的缺陷就在于它可能会选错执行计划。 解析多表关联的sql时，可能的执行路径太多，不可能全部遍历。 假设sql都是单独执行的，没有考虑缓存。。。。 索引全扫描(INDEX FULL SCAN)，扫描目标索引所有叶子块的所有索引行。 走索引全扫描能够达到排序的效果，避免了对该索引的索引键值列的真正排序操作。 算法如何写好while loop需要思考如下几点： 从上一迭代到下一迭代是怎么转变的，涉及什么数据变化，数据怎么变化 迭代的终止条件是什么 uuid的作用，优缺点","tags":[],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"HashMap","date":"2018-11-05T13:28:21.000Z","path":"wiki/Java/HashMap/","text":"存储结构HashMap内部采用数组+链表+红黑树来实现。如下图所示。 Node是HashMap的内部类，用来表示一个键值对，实现了Map.Entry接口 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; 几个重要字段 123456int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子，默认为0.75// 内部结构发生变化的次数，迭代器遍历时若发生变化会抛出ConcurrentModificationException异常int modCount;int size; // 实际存的键值对数量Node&lt;K,V&gt;[] table // 数组 当 size &gt; (threshold = table.length * loadFactor)时，就要对数组进行扩容，数组扩容后的大小是原来的两倍。 实现hash算法123456static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;// 来定位哈希桶数组索引位置tab[i = (n - 1) &amp; hash] 通过key的hashCode()的高16位异或低16位来计算hash，使得高低bit都参与到hash计算来。计算hash后，需要根据hash值确定键值对在数组中的位置。一般通过对数组取模h%length来确定，这里通过(n - 1) &amp; hash同样达到了取模的目的，但是效率更高。下面证明下： X % 2^n = X &amp; (2^n – 1) 2^n表示成2进制就是1000…0(n个0)。2^n - 1为0111..11(n个1)。 此时X &amp; (2^n – 1) 就相当于取X的2进制的最后n位数。 从2进制角度来看，X / 2^n相当于 X &gt;&gt; n，即把X右移n位，此时得到了X / 2^n的商，而被移掉的部分(后n位)，则是X % 2^n，也就是余数。 put方法put方法流程如下图 扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 重点在这下面，上面是确定容量的，这里进行数组转移，以一个新数组替换原来的 @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) // 构建新的数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 遍历老数组的Node for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 便于GC oldTab[j] = null; // 链表就一个元素，直接放到新数组 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 是红黑树节点，节点数超过8 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 正常链表 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; // 循环遍历链表的节点 next = e.next; // 分为两种情况，链表上节点会分到两个桶下面 // 这里进行链表的拆分 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将链表放入新数组中，Node的先后顺序没有变 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // e.hash * old_n == 1 的放在新数组[j+old_n]位置处 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 前面说了通过(n - 1) &amp; hash来确定Node在数组中的位置，扩容后n变为原来的2倍。也就是说n-1与扩容前相比其位标志上左边多出一位为1，这时候与hash进行与计算，则计算结果取决于该位上hash是0还是1，如果是0，则计算结果与扩容前一致，如果是1，则该位结果为1，即为原来的值+扩容前的n值。 在Java7中，链表在转移的时候顺序会被导致，多线程resize的时候会形成环形链表导致put时出现死循环，Java8已经没这个问题了。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"集合","slug":"集合","permalink":"http://polyval.github.io/Wiki/tags/集合/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"CountDownLatch&CyclicBarrier","date":"2018-11-03T12:18:21.000Z","path":"wiki/Java/CountDownLatch/","text":"CountDownLatch的作用是使得一个或多个线程等待直到其他线程完成操作。 CyclicBarrier的作用是可以让一组线程达到一个屏障时被阻塞，直到最后一个线程达到屏障时，所有被阻塞的线程才能继续执行。 实际场景：多线程去后台查数据，需要所有数据全部获取到后再处理。 CountDownLatch原理还是利用AQS来实现，其对外暴露的三个重要方法为。 CountDownLatch(int) 其实就是设置sync的state。这个值表示countDown方法需要被调用多少次调用await的方法才会被唤醒。 await，调用的是sync.acquireSharedInterruptibly(1); 调用该方法的线程会阻塞到state为0 countDown，调用的是sync.releaseShared(1); 调用该方法state计数减1 原理很简单。 1234567891011121314151617// 阻塞到state为0protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125;protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; // 计数减1 int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; CyclicBarrier一个高级队构造函数：CyclicBarrier(int parties, Runnable barrierAction)，barrierAction任务会在所有线程到达屏障后执行。 CyclicBarrier和CountDownLatch区别CountDownLatch的计数器只能使用一次，CyclicBarrier可以用reset`方法将计数器重置。因此CyclicBarrier可以处理更加复杂的业务场景。CountDownLatch一般用于某些线程等待若干个其他线程执行完任务之后，它才执行；而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； SemaphoreSemaphore可以用来控制同时访问特定资源的线程数量。实现比较简单，可参看Semaphore","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"ReentrantLock","date":"2018-11-01T03:28:21.000Z","path":"wiki/Java/ReentrantLock/","text":"ReentrantLock实现了Lock的接口。ReentrantLock相比synchronized提供了更多的功能。Lock接口的方法如下 lock lockInterruptibly，可中断的锁获取操作，在获取锁的过程中，线程可以响应中断。被中断时会抛出InterruptedException。 tryLock，非阻塞的获取锁，获取不到就立即返回。 tryLock(time)，超时获取锁，以下情况会返回：时间内获取到了锁，时间内被中断，时间到了没有获取到锁。 unlock condition 获取条件实例。 可重入锁ReentrantLock是可重入锁，什么是可重入锁呢，可重入锁是可重复可递归调用的锁，同一个线程外层函数获取到锁后，内层函数仍然有获取锁的代码，但不受影响。如果锁不可重入，则在线程再次调用获取锁的方法时，会发现锁被持有而发生死锁。如下代码，同一个线程调用lock方法两次，第二次则会发生死锁。 123456789public void lock() &#123; Thread current = Thread.currentThread(); //这句是很经典的“自旋”语法 for (;;) &#123; if (!owner.compareAndSet(null, current)) &#123; return; &#125; &#125;&#125; ReentrantLock通过一个计数器来实现可重入。 1234567891011121314151617181920final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 这里判断是否当前线程获取到锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; // 最大可重入次数限制。 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 为什么要用计数器，因为获取多少次锁就要释放多少次，如果最里面一层释放了锁就直接把锁释放掉了，那么原来外层有锁的逻辑就被改变了，外层此时处于没锁的状态。 公平锁和非公平锁ReentrantLock提供了两种锁的实现。公平锁和非公平锁，所谓公平锁是指线程获取锁的顺序按照排队顺序来，而非公平锁获取锁的顺序不定。 Sync继承自AQS，而FairSync 和NonfairSync继承自Sync来实现公平锁和非公平锁。 先来看看非公平锁的lock方法，公平锁和非公平锁也就这两个方法有区别。 12345678910111213final void lock() &#123; // 快速CAS来获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // CAS获取失败通过AQS中的acquire方法来获取，将state设为1 acquire(1);&#125;protected final boolean tryAcquire(int acquires) &#123; // 参看上节中代码，支持了可重入 return nonfairTryAcquire(acquires);&#125; 公平锁的lock方法 1234567891011121314151617181920212223242526272829final void lock() &#123; acquire(1);&#125;/** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 没有获取到锁 if (c == 0) &#123; // 判断前面没有节点才会去获取锁，前面有节点时acquire方法会将其加入到同步队列，进队列后就可以保证FIFO。两者结合保证了公平锁的实现。 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 两种锁的unlock方法一样。 12345678910111213141516171819public void unlock() &#123; sync.release(1);&#125;protected final boolean tryRelease(int releases) &#123; // 计数器减1 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 表示完全释放掉锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; // 设置state为减后的 setState(c); return free;&#125; 公平锁和非公平锁的区别公平锁的整体吞吐量往往不高，但是可以防止饥饿现象。非公平锁线程切换次数要少些，所以吞吐量较高。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"ReentrantReadWriteLock","date":"2018-10-31T23:28:21.000Z","path":"wiki/Java/ReentrantReadWriteLock/","text":"ReentrantReadWriteLock是读写锁，其维护了一对锁，一个读锁和一个写锁，读写锁在同一时刻可以允许多个读线程访问，在写线程访问时，则所有线程均被阻塞。适用于读多写少的场景。 如何在一个int变量上维护多个读线程和一个写线程的状态。读写锁将int变量分成了两个部分，高16位表示读，低16位表示写。通过位运算来实现状态的改变。 写锁写锁是独占锁，获取锁时重写tryAcquire即可 12345678910111213141516171819202122232425262728293031323334protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); //获取代表写锁的值，采用位运算来实现 int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) // 存在读锁或者当前线程不是已经获取写锁的线程 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; // 在c=0时即没有读锁和写锁时，非公平锁会交给AQS去创建头节点然后获取再次调用获取锁 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;&#125; 在读锁存在的时候，写锁不能被获取，原因在于：读写锁要保证写锁的操作要对读锁可见，如果存在读锁时写锁获取到，写线程的操作就对读线程不可见。而写锁一旦被获取，则其他读写线程的后续访问就会被阻塞。 方法writerShouldBlock由Sync的子类来实现，以此来区分公平锁和非公平锁。 写锁的释放操作和ReentrantLock类似，需要保证可重入性。 读锁读锁是共享锁，利用tryAcquireShared和tryReleaseShared来进行锁的获取和释放。如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态，如果当前线程获取了写锁或者写锁未被获取，则当前线程增加读状态，获取读锁。 读锁的每次释放都会减少读状态。注意在增加读状态和减少读状态时都需要保证线程安全(CAS)，因为可能有多个线程对状态进行修改。 锁降级锁降级指的是写锁降级成为读锁：获取到写锁，再获取到读锁，随后释放写锁的过程。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"Condition","date":"2018-10-28T03:28:21.000Z","path":"wiki/Java/Condition/","text":"Condition接口定义的几个方法如下： 其中，await方法类似于Object的wait方法，而signal和signalAll则分别对应于notify和notifyAll方法。 Condition其实现类在AQS中以内部类ConditionObject的形式存在。condition由锁的方法Lock.newCondition()来获取，且一个Lock可获取多个Condition，而不像Object只能设置一个条件。 下面说一下ConditionObject的await和signal方法。 await在调用该方法时，当前线程需要获取到与该Condition关联的锁，如果不加锁进入该方法，可能会导致其他线程调用signal方法时，还没进入到await方法，导致这个信号丢失，而不起任何效果。调用该方法后，线程释放锁，进入睡眠状态，在以下四种情况下线程会被唤醒 其他线程调用signal方法，当前线程恰好被选中唤醒 其他线程调用signalAll方法 被其他线程中断 中断是让线程停止当前所做的事去做别的事情的一个标志。停止当前所做的事不代表线程就占用CPU在做什么，线程在睡眠也叫做线程所做的事。调用Thread.interrupt()方法可以设置目标线程的中断状态，至于线程如何响应中断，则看程序是如何写的。 发生虚假唤醒(spurious wakeup) 虚假唤醒时指线程在没有收到线程唤醒信号的时候醒了过来。await方法在jvm执行时实质是调用了底层pthread_cond_wait/pthread_cond_timedwait函数，而pthread_cond_wait可能在没收到信号时返回。同时，由于编码不规范也会产生虚假唤醒，举个例子 线程A获取锁，发现队列空，因此wait，线程B向队列插入数据，改变条件变量，发出signal，线程C获取到锁，将数据移除，等到A获取锁从wait状态醒来时，应该是去队列移除数据的，但是此时的队列已经为空，这个唤醒是虚假唤醒。 pthread_cond_wait的作者认为既然编程不规范也会导致虚假唤醒，那么就交由上层来避免虚假唤醒，而不是底层来实现。 由于虚假唤醒的存在，await方法应该在循环中调用。 await的基本流程如下： 生成并添加代表线程的Node节点到条件队列 释放锁 阻塞直到Node被移到同步队列 重新获取锁 12345678910111213141516171819202122232425262728293031public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); //新节点入条件队列 Node node = addConditionWaiter(); //当前线程已持有锁，但由于要被阻塞，为不影响其他线程，需要先释放锁 int savedState = fullyRelease(node); int interruptMode = 0; // 阻塞直到Node被移到锁队列 while (!isOnSyncQueue(node)) &#123; // 阻塞 LockSupport.park(this); /** * 检测中断，一旦发生中断 * 1.将条件队列中因中断而唤醒的节点进行转移(注意此处是中断) * 2.退出循环 -&gt; 接下来会在循环外进行中断处理 */ if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 重新尝试获取同步锁，获取成功后且被中断，当中断模式为抛出异常时，需要设置为重新中断，补充：acquireQueued会返回获取锁过程中线程是否有过中断，true则说明发生过中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 若当前节点存在后继节点时，需要执行出队操作 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); //interruptMode != 0 说明是需要进行中断处理的 if (interruptMode != 0) //执行中断处理 reportInterruptAfterWait(interruptMode);&#125; Signalsignal做的事情 清除节点： 从条件队列中移除第一个节点 节点转移： 将条件节点转换为同步节点，即从条件队列转移到同步队列 唤醒节点： 将转移成功的节点重新唤醒 当cancellation(超时或者中断)和signal几乎同时发生时，会存在竞争，根据Java规范，如果中断先发生，await在重新获取到锁后，抛出InterruptException，如果中断后于signal，则不抛出异常，只需修改线程中断的标志位。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"CAS","date":"2018-10-23T03:28:21.000Z","path":"wiki/Java/CAS/","text":"CAS，Compare and set。是Java中实现原子操作的重要手段，在Java并发工具中起着重要作用。 CAS是什么CAS是一种多线程同步中常用的原子操作。在CAS中，有三个重要的参数：内存值V、旧的预期值A、要更新成为的值B，当且仅当内存值V等于旧的预期值A时，才把内存值V更改成B。基于CAS操作，可以实现乐观锁机制，乐观锁的思想是认为数据一般情况下不会发生冲突，所以在数据提交更新的时候，才会对冲突进行检测。乐观锁是种思想，而CAS是这种思想的一种实现方式。注意，CAS是一种操作，CAS一般配合自旋来实现乐观锁机制。 让我们以AtomicInteger为例来看看CAS的应用。 1234567private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe();private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, \"value\");public final int addAndGet(int delta) &#123; return U.getAndAddInt(this, VALUE, delta) + delta;&#125; 其中，VALUE是变量值在内存中的地址，delta是在原值基础上要加的值。 调用unsafe的方法 12345678910111213public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v;&#125;public final boolean weakCompareAndSetInt(Object o, long offset, int expected, int x) &#123; return compareAndSetInt(o, offset, expected, x); &#125; 其中，getIntVolatile 和compareAndSetInt都是调用的native方法，从getIntVolatile可以看出利用CAS进行不断重试，注意，CAS只是一次操作，native方法compareAndSetInt的四个参数：对象、对象的地址、预期值和修改值。 CAS缺点竞争激烈时开销大在竞争激励时，CAS失败的概率比较大，如果循环CAS，则可能出现CAS长时间不成功会给CPU带来非常大的执行开销。 只能实现一个共享变量的原子操作可以使用AtomicReference类来保证引用对象的原子性，把多个变量放在一个对象里进行CAS操作。 ABA问题ABA问题即，如果一个值原来是A，中间变成了B，后来又变成了A。这时候CAS检查时会认为没有发生变化。这就是ABA问题。ABA问题会带来什么隐患呢。 ABA隐患在Java这种垃圾回收型的语言中，可以避免一种比较典型的ABA问题。以C++为例 A common case of the ABA problem is encountered when implementing a lock-free data structure. If an item is removed from the list, deleted, and then a new item is allocated and added to the list, it is common for the allocated object to be at the same location as the deleted object due to optimization. A pointer to the new item is thus sometimes equal to a pointer to the old item which is an ABA problem. C++中，对指针进行CAS操作，即使两个指针相同，它们也未必指向同一个对象。有可能是第一个指针所指向的内存被释放后，第二个对象恰好分配在相同地址的内存。 而在GC环境中，两个引用相等，其指向对对象必然相等，因为只要对象存在引用，其对象的内存就不会被回收掉，那么新new出来的对象地址也不可能重复。 当然，Java中也存在ABA问题，在链表结构中容易出现。 如下例子： 线程1准备用CAS将变量的值由A替换为B，在此之前，线程2将变量的值由A替换为C，又由C替换为A，然后线程1执行CAS时发现变量的值仍然为A，所以CAS成功。但实际上这时的现场已经和最初不同了，尽管CAS成功，但可能存在潜藏的问题，例如下面的例子： 现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B： head.compareAndSet(A,B) 在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时处于游离状态： 此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为： 其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。 ABA问题解决ABA问题可以通过版本号进行解决，利用AtomicStampedReference可以解决 这个问题，AtomicStampedReference主要维护包含一个对象引用以及一个可以自动更新的整数”stamp”的pair对象来解决ABA问题。 利用CAS实现线程安全的单例不使用synchronized和lock，如何实现一个线程安全的单例？可以利用CAS。 12345678910111213141516171819public class Singleton &#123; private static final AtomicReference&lt;Singleton&gt; INSTANCE = new AtomicReference&lt;Singleton&gt;(); private Singleton() &#123;&#125; public static Singleton getInstance() &#123; for (;;) &#123; Singleton singleton = INSTANCE.get(); if (null != singleton) &#123; return singleton; &#125; singleton = new Singleton(); if (INSTANCE.compareAndSet(null, singleton)) &#123; return singleton; &#125; &#125; &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"Linux命令","date":"2018-10-21T05:08:29.000Z","path":"wiki/操作系统/Linux命令/","text":"psps -ef | grep &quot;&quot; zgrepxargsfindfind . -name &quot;&quot; | xargs zgrep &quot;&quot; 查找端口被占用的程序lsof -i :&lt;port&gt;","tags":[],"categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://polyval.github.io/Wiki/categories/操作系统/"}]},{"title":"Java分析工具","date":"2018-10-21T03:28:21.000Z","path":"wiki/Java/Java分析工具/","text":"jmap输出对象实例个数jmap -histo &lt;pid&gt; &gt; a.log 查看应用代码实例的个数，对于出现内存泄露的情况，可以快速定位出是哪个对象引起的。 输出堆文件jmap -dump:format=b,file = a.dat &lt;pid&gt; 查看进程堆内存使用情况jmap -heap &lt;pid&gt; jhat查看dump文件jhat -port 9998 /tmp/var/dump.dat 然后在浏览器中输入localhost:9998即可查看 jstackjstat监控GCjstat -gcutil &lt;pid&gt; &lt;interval&gt; &lt;count&gt; jps输出JVM中运行的进程状态信息 jConsolejinfojVisualvmeclipse memory analyzerdump分析工具 BtraceGreys-Anatomy在线问题诊断工具","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"CAP定理","date":"2018-10-21T03:28:21.000Z","path":"wiki/分布式/CAP定理/","text":"CAP定理分布式系统中有三个指标 Consistency 一致性 Avaliability 可用性 Partition tolerance 分区容错 CAP定理认为这三个指标不可能同时做到。 Patition tolerance分区容错指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 Consistency等同于所有节点访问同一份最新的数据副本 Avaliability可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。 CAP权衡CAP权衡有三种情况 CA without P这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。 对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。 CP without A如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。 一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。 AP wihtout C要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。 这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。 你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。 但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。","tags":[{"name":"分布式","slug":"分布式","permalink":"http://polyval.github.io/Wiki/tags/分布式/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"http://polyval.github.io/Wiki/categories/分布式/"}]},{"title":"Git","date":"2018-10-21T03:28:21.000Z","path":"wiki/工具/Git/","text":"原理四大区 工作区(Working Directory) 暂存区(Stage or index) 本地库 远程库 各区的转换图如下 HEADHEAD是一个特殊的指针，指向当前工作分支的最新commit 常用命令cherry-pick再次应用已经存在的commits，可以将其他分支的某些commit应用到当前分支。 git cherry-pick &lt;commit id&gt;git cherry-pick &lt;start-commit-id&gt;^..&lt;end-commit-id&gt;应用这一区段的commits，左闭右闭。 git cherry-pick --abort取消操作 stash在某些分支上进行了改动，但是还没有完成，也没有提交，这个时候又要切到另外一个分支上进行工作。 git stashgit stash listgit stash apply恢复到上次stash的状态 git stash pop恢复到上次stash的状态并去掉上次的stash revert将某些commit回退掉，同时会生成新的commit来记录这次操作 git revert &lt;commit&gt;git revert HEAD~3撤销倒数第四次commit。 reset三种模式 – mixed。回退暂存区，工作区不动。也就是说改动的文件不会动但是会回退到未提交状态。—mixed是默认选项。 – hard。 暂存区和工作区都会被回退掉。 – soft。 暂存区和工作区都不会动，回退到指定的commit之后，这个commit之后的文件都处于changed to be committed状态。 git resetgit add 之后想撤销就可以用这个命令 git reset --hard HEAD~3最近三次提交不想要了，也不想再看到它们。可以使用这个命令。 git reset -- &lt;file&gt;回退单个文件。 reflogref + log reflog命令可以查看所有的历史操作记录 比如误操作用了git reset --hard HEAD^ 这时候用git log是找不到原来的commit的，这时候可以用git reflog找到commit id来进行恢复。 rebase将某个分支的修改移动到当前分支，依次将提交作用到当前分支，作用到过程中生成新的提交记录，提交信息默认与原来的一致。 应用场景","tags":[],"categories":[{"name":"工具","slug":"工具","permalink":"http://polyval.github.io/Wiki/categories/工具/"}]},{"title":"Spring Cloud","date":"2018-10-21T03:28:21.000Z","path":"wiki/微服务/Spring Cloud/","text":"配置管理服务治理服务注册服务向注册中心登记自己提供的服务 服务发现通过服务名发起请求调用 断路器智能路由","tags":[{"name":"微服务","slug":"微服务","permalink":"http://polyval.github.io/Wiki/tags/微服务/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"http://polyval.github.io/Wiki/categories/微服务/"}]},{"title":"AQS","date":"2018-10-21T03:28:21.000Z","path":"wiki/Java/AQS/","text":"AbstractQueuedSynchronizer是一个抽象类，为Java中各种Synchronizers(同步器)的实现提供了一个模版框架。 Synchronizers是什么？Synchronizers是实现多线程通信、同步的工具和手段。如锁、Semaphore、阻塞队列、CyclicBarrier、CountDownLatch等。同步器通常包含如下几个部分来实现多线程同步 状态（state） 访问控制（access control） 状态转化（state change） 通知策略（Notification Strategy） Test and Set方法 Set方法 当然，不是所有同步器都需要这些东西，有些同步器也可能通过其他方式来实现同步。 访问控制利用同步器的同步状态来决定线程是否可以进入临界区(发生竞争的代码段)。线程进入后，改变状态，从而阻塞(可能)其他线程。有时候，当一个线程改变状态后，可能需要通知其他线程状态发生了改变。这几个过程如下两个例子： 12345678910111213141516171819public class Lock&#123; private boolean isLocked = false; // state public synchronized void lock() throws InterruptedException&#123; // access control while(isLocked)&#123; // //wait strategy - related to notification strategy wait(); &#125; isLocked = true; // state change &#125; public synchronized void unlock()&#123; isLocked = false; notify(); //notification strategy &#125;&#125; 1234567891011121314151617181920212223public class BoundedSemaphore &#123; private int signals = 0; // state private int bound = 0; // state public BoundedSemaphore(int upperBound)&#123; this.bound = upperBound; &#125; public synchronized void take() throws InterruptedException&#123; // access control while(this.signals == bound) wait(); //state change this.signals++; this.notify(); &#125; public synchronized void release() throws InterruptedException&#123; while(this.signals == 0) wait(); //state change this.signals--; this.notify(); // notification strategy &#125;&#125; 同步器最重要的两类方法同步器最重要的两类方法是：acquire和release方法。acquire方法阻塞调用这个方法的线程直到同步状态满足访问控制要求，release方法改变同步状态，这个同步状态的改变有可能使得一个或多个阻塞线程恢复。 acquire的逻辑如下123456789while (当前同步状态不允许进行acquire) &#123; 如果当前线程不在队列则将其加入队列； 有可能阻塞当前线程；&#125;如果当前线程在队列中则出队列 release的逻辑如下 123更新同步状态if (同步状态有可能使某些阻塞线程acquire) 去阻塞这些线程 具体参考synchronizer，Doug Lea的论文 AQS提供的功能作为一个框架，AQS主要提供了对同步状态的原子操作、阻塞与唤醒线程、队列管理线程等功能，在上一节我们知道了我们需要对同步状态进行改变，这个改变需要保证原子性，通过同步状态来实现访问控制，从而实现线程的阻塞与唤醒。 同步状态AQS中通过一个带volatile语义的int变量来维护同步状态。提供getState、setState和compareAndSetState方法来访问和更新状态，AQS的具体实现类需要根据这些方法来实现tryAcquire和tryRelease方法。 阻塞(Blocking)java.util.concurrent.locks提供了LockSupport类来实现线程的阻塞与唤醒。 LockSupport.park阻塞线程，LockSupport.unpark唤醒线程。 同步队列同步队列用来维护线程队列，它是一个FIFO队列。来完成线程获取锁的排队工作。 Condition队列等待队列，通过内部ConditionObject构成，当Condition调用await()方法后，线程将会加入等待队列中，而当Condition调用signal()方法后，线程将从等待队列转移动同步队列中进行锁竞争。Condition提供的方法类似于Object对象的监视器方法wait()、notify()和notifyAll()。关于Condition，参考 详解同步队列是一个FIFO双向队列，在该队列中，一个Node节点表示一个线程。 Node每个线程用一个Node表示。Node有个重要的字段waitStatus，表示节点线程的状态。其值含义如下： SIGNAL，表示当前节点的后继节点处于或即将处于阻塞状态，当前节点在release或者cancel的时候需要唤醒后继节点 CANCELLED，表示当前节点线程由于超时或者中断而被取消 CONDITION，表示当前节点在条件队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()后，改节点将会从条件队列中转移到同步队列中，加入到同步状态的获取中 PROPAGATE，在共享模式下，后续节点传播唤醒的操作。 默认值 除了waitStatus，Node还保存了线程的引用、前驱节点、后继节点和条件队列中用到的下一节点(nextWaiter)。其中，还有两个静态变量 1234/** Marker to indicate a node is waiting in shared mode */static final Node SHARED = new Node();/** Marker to indicate a node is waiting in exclusive mode */static final Node EXCLUSIVE = null; 共享模式和独占模式是什么意思？共享模式指的是允许多个线程获取同一个锁而且可能获取成功，独占模式指的是一个锁如果被一个线程持有，其他线程必须等待。 同步队列结构图如下： 我们先来看看独占模式下的acquire和release两个重要方法。 acquireacquire的流程图如下 acquire方法是AQS提供的模版方法，其中tryAcquire方法由子类来实现。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire，由子类实现，去尝试获取锁 addWaiter，创建一个新节点加入到队尾 acquireQueued，如果前驱节点为头节点，循环去获取锁，否则线程等待。 我们来看一下三个线程同时去争取锁的时候发生了什么。 首先，tryAcquire中，一般是通过CAS来实现对锁的竞争，这三个线程其中一个CAS成功，另外两个失败。它们的tryAcquire返回false； addWaiter方法将这两个失败的线程以EXCLUSIVE类型节点加入同步队列。 1234567891011121314151617private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 如果队尾节点不为null if (pred != null) &#123; // 直接CAS入队尾 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 队尾为空或者CAS失败 enq(node); return node;&#125; 首先判断是否存在尾节点，如果存在，则CAS将新生成的节点设置为尾节点。如果CAS失败或者尾节点不存在，则用enq将其加入尾节点，总之，addWaiter就是将创建新节点加入到队尾。 1234567891011121314151617private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 尾节点不存在，需要初始化 if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 尾节点有了 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 这里两个线程进入，其中一个线程发现尾节点为空，则CAS生成尾节点，另外一个节点CAS失败或者在if时就判断尾节点生成了，直接将自己设成尾节点即可。 acquireQueued方法大概过程如下： 对于同时进入的线程2和线程3，对于线程2前一个节点为头节点，会再尝试获取锁一次，如果失败，则将头节点的waitStatus改成SIGNAL，下次循环的时候会再次去尝试获取锁，如果还是失败，其waitStatus为SIGNAL，则通过LockSupport将线程挂起；对于线程3，由于它的前驱节点为线程2，根据FIFO，需要等至少线程2获取到锁3才去获取锁，因此3只需将2点waitStatus改成SIGNAL，然后再检查一下自己是否有资格去获取锁，没有则挂起。 这里有个问题，这个FIFO顺序是否就实现了公平锁呢？ 让我们看看线程1释放锁后这个锁是怎么传递到。 release线程1在释放锁的时候的操作如下 12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后继节点 unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease同样由子类来实现，在tryRelease中，1会释放掉锁。会将state从1改成0，此时，如果线程4来了，那么这个锁就有可能被4给拿去而不是依次从2到3，因此上节中的问题，FIFO同步队列并不能保证锁的公平获取，它只能保证入了队列的线程获取锁的一个先后顺序，这也是为什么ReentrantLock中需要实现公平锁的逻辑。 当1释放锁后，判断队列中是否有节点，如果有节点，则去通知节点来拿锁。unparkSuccessor主要做三件事情： 将队头的waitStatus设置为0. 通过从队列尾部向队列头部移动，找到最后一个waitStatus&lt;=0的那个节点，也就是离队头最近的没有被cancelled的那个节点，队头这个时候指向这个节点。 将这个节点唤醒，这个时候线程1已经出队列了。 acquireShared共享模式与独占模式acquire逻辑大致相同，区别在于入队列后获取锁成功后的操作，如果获取锁成功，共享模式会判断后继节点是否是共享模式，如果是，则立即对其进行唤醒操作。 releaseShared共享模式下的release逻辑也是要保证释放锁的时候往后传播，使得所有共享模式的节点都可以被唤醒。 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://polyval.github.io/Wiki/tags/并发/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"Java内存优化","date":"2018-10-21T03:28:21.000Z","path":"wiki/Java/Java内存优化/","text":"常驻内存排查内存泄漏重用对象String.intern()在某服务中，通过与其他进程通讯获取到格式为byte[]的字段，将byte[]转化成String的时候利用new String(byte[])方法，但是string很多是相同的，产生了大量相同的string对象，而且这些对象是程序中当作缓存来用一直存在于内存中，采用String.intern()对String对象进行缓存，降低了内存占用30M。 Integer.valueOf()只需一个实例的对象一定要使用单例对象池技术使用小数据类型减少线程数去垃圾回收机制System.arraycopy ()临时内存减少不必要的对象拷贝，重写对象的clone方法容器大小预估容器在扩容时会产生大量临时对象，对容器大小进行预估传入初始值可以减少容器的扩容","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"CPU占用过高定位","date":"2018-10-06T16:28:21.000Z","path":"wiki/Java/CPU占用过高定位/","text":"方法1找到CPU占用过高的线程top -p &lt;pid&gt; 输入H查看该进程的所有线程的统计情况，从而找到CPU占用过高的线程； 将线程id转化为16进制就是Java堆栈中对应的nid 查看Java堆栈获取Java堆栈 在线程堆栈中找到nid=上一步nid的线程堆栈 找到对应的线程id 如果该线程正在执行Java代码，说明是该Java代码导致的CPU高 如果线程在执行native code，说明是本地代码导致的CPU高。通过pstack pid获取本地线程堆栈，在本地线程堆栈中找到对应线程，借助本地线程堆栈进行定位。 找不到对应的线程id有两种可能 虚拟机自身代码导致的如堆内存枯竭导致的频繁Full GC，或者虚拟机的bug。此时可以通过本地线程堆栈进行定位。 重新创建了线程来执行方法2多次打印线程堆栈，找到相同的代码段","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"Java内存溢出的情况","date":"2018-10-06T16:28:21.000Z","path":"wiki/Java/Java内存溢出的情况/","text":"1、java.lang.OutOfMemoryError:Java heap spaceJava应用程序在启动时会指定所需要的内存大小，它被分割成两个不同的区域：Heap space（堆空间）和Permgen（永久代）： JVM内存模型示意图 这两个区域的大小可以在JVM（Java虚拟机）启动时通过参数 1-Xmx 和 1-XX:MaxPermSize 设置，如果你没有显式设置，则将使用特定平台的默认值。 当应用程序试图向堆空间添加更多的数据，但堆却没有足够的空间来容纳这些数据时，将会触发java.lang.OutOfMemoryError: Java heap space异常。需要注意的是：即使有足够的物理内存可用，只要达到堆空间设置的大小限制，此异常仍然会被触发。 原因分析触发java.lang.OutOfMemoryError: Java heap space最常见的原因就是应用程序需要的堆空间是XXL号的，但是JVM提供的却是S号。解决方法也很简单，提供更大的堆空间即可。除了前面的因素还有更复杂的成因： 流量/数据量峰值：应用程序在设计之初均有用户量和数据量的限制，某一时刻，当用户数量或数据量突然达到一个峰值，并且这个峰值已经超过了设计之初预期的阈值，那么以前正常的功能将会停止，并触发java.lang.OutOfMemoryError: Java heap space异常。 内存泄漏：特定的编程错误会导致你的应用程序不停的消耗更多的内存，每次使用有内存泄漏风险的功能就会留下一些不能被回收的对象到堆空间中，随着时间的推移，泄漏的对象会消耗所有的堆空间，最终触发java.lang.OutOfMemoryError: Java heap space错误。 示例①、简单示例首先看一个非常简单的示例，下面的代码试图创建2 x 1024 x 1024个元素的整型数组，当你尝试编译并指定12M堆空间运行时（java -Xmx12m OOM）将会失败并抛出java.lang.OutOfMemoryError: Java heap space错误，而当你指定13M堆空间时，将正常的运行。 123456class OOM &#123; static final int SIZE=2*1024*1024; public static void main(String[] a) &#123; int[] i = new int[SIZE]; &#125;&#125; 运行如下： 12345D:\\&gt;javac OOM.javaD:\\&gt;java -Xmx12m OOMException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at OOM.main(OOM.java:4)D:\\&gt;java -Xmx13m OOM ②、内存泄漏示例在Java中，当开发者创建一个新对象（比如：new Integer(5)）时，不需要自己开辟内存空间，而是把它交给JVM。在应用程序整个生命周期类，JVM负责检查哪些对象可用，哪些对象未被使用。未使用对象将被丢弃，其占用的内存也将被回收，这一过程被称为垃圾回收。JVM负责垃圾回收的模块集合被称为垃圾回收器（GC）。 Java的内存自动管理机制依赖于GC定期查找未使用对象并删除它们。Java中的内存泄漏是由于GC无法识别一些已经不再使用的对象，而这些未使用的对象一直留在堆空间中，这种堆积最终会导致java.lang.OutOfMemoryError: Java heap space错误。 我们可以非常容易的写出导致内存泄漏的Java代码： 1234567891011121314151617181920212223242526public class KeylessEntry &#123; static class Key &#123; Integer id; Key(Integer id) &#123; this.id = id; &#125; @Override public int hashCode() &#123; return id.hashCode(); &#125; &#125; public static void main(String[] args) &#123; Map&lt;Key,String&gt; m = new HashMap&lt;Key,String&gt;(); while(true) &#123; for(int i=0;i&lt;10000;i++) &#123; if(!m.containsKey(new Key(i))) &#123; m.put(new Key(i), &quot;Number:&quot; + i); &#125; &#125; &#125; &#125;&#125; 代码中HashMap为本地缓存，第一次while循环，会将10000个元素添加到缓存中。后面的while循环中，由于key已经存在于缓存中，缓存的大小将一直会维持在10000。但事实真的如此吗？由于Key实体没有实现equals()方法，导致for循环中每次执行m.containsKey(new Key(i))结果均为false，其结果就是HashMap中的元素将一直增加。 随着时间的推移，越来越多的Key对象进入堆空间且不能被垃圾收集器回收（m为局部变量，GC会认为这些对象一直可用，所以不会回收），直到所有的堆空间被占用，最后抛出java.lang.OutOfMemoryError:Java heap space。 上面的代码直接运行可能很久也不会抛出异常，可以在启动时使用-Xmx参数，设置堆内存大小，或者在for循环后打印HashMap的大小，执行后会发现HashMap的size一直再增长。 解决方法也非常简单，只要Key实现自己的equals方法即可： 12345678Overridepublic boolean equals(Object o) &#123; boolean response = false; if (o instanceof Key) &#123; response = (((Key)o).id).equals(this.id); &#125; return response;&#125; 解决方案第一个解决方案是显而易见的，你应该确保有足够的堆空间来正常运行你的应用程序，在JVM的启动配置中增加如下配置： 1-Xmx1024m 上面的配置分配1024M堆空间给你的应用程序，当然你也可以使用其他单位，比如用G表示GB，K表示KB。下面的示例都表示最大堆空间为1GB： 1234java -Xmx1073741824 com.mycompany.MyClassjava -Xmx1048576k com.mycompany.MyClassjava -Xmx1024m com.mycompany.MyClassjava -Xmx1g com.mycompany.MyClass 然后，更多的时候，单纯地增加堆空间不能解决所有的问题。如果你的程序存在内存泄漏，一味的增加堆空间也只是推迟java.lang.OutOfMemoryError: Java heap space错误出现的时间而已，并未解决这个隐患。除此之外，垃圾收集器在GC时，应用程序会停止运行直到GC完成，而增加堆空间也会导致GC时间延长，进而影响程序的吞吐量。 如果你想完全解决这个问题，那就好好提升自己的编程技能吧，当然运用好Debuggers, profilers, heap dump analyzers等工具，可以让你的程序最大程度的避免内存泄漏问题。 2、java.lang.OutOfMemoryError:GC overhead limit exceeded默认情况下，当应用程序花费超过98%的时间用来做GC并且回收了不到2%的堆内存时，会抛出java.lang.OutOfMemoryError:GC overhead limit exceeded错误。具体的表现就是你的应用几乎耗尽所有可用内存，并且GC多次均未能清理干净。 原因分析java.lang.OutOfMemoryError:GC overhead limit exceeded错误是一个信号，示意你的应用程序在垃圾收集上花费了太多时间但却没有什么卵用。默认超过98%的时间用来做GC却回收了不到2%的内存时将会抛出此错误。那如果没有此限制会发生什么呢？GC进程将被重启，100%的CPU将用于GC，而没有CPU资源用于其他正常的工作。如果一个工作本来只需要几毫秒即可完成，现在却需要几分钟才能完成，我想这种结果谁都没有办法接受。 所以java.lang.OutOfMemoryError:GC overhead limit exceeded也可以看做是一个fail-fast（快速失败）实战的实例。 示例下面的代码初始化一个map并在无限循环中不停的添加键值对，运行后将会抛出GC overhead limit exceeded错误： 123456789public class Wrapper &#123; public static void main(String args[]) throws Exception &#123; Map map = System.getProperties(); Random r = new Random(); while (true) &#123; map.put(r.nextInt(), &quot;value&quot;); &#125; &#125;&#125; 当我们使用如下参数启动程序时： 1java -Xmx100m -XX:+UseParallelGC Wrapper 我们很快就可以看到程序抛出java.lang.OutOfMemoryError: GC overhead limit exceeded错误。但如果在启动时设置不同的堆空间大小或者使用不同的GC算法，比如这样： 1java -Xmx10m -XX:+UseParallelGC Wrapper 我们将看到如下错误： 12345Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Hashtable.rehash(Unknown Source) at java.util.Hashtable.addEntry(Unknown Source) at java.util.Hashtable.put(Unknown Source) at cn.moondev.Wrapper.main(Wrapper.java:12) 使用以下GC算法：-XX:+UseConcMarkSweepGC 或者-XX:+UseG1GC，启动命令如下： 12java -Xmx100m -XX:+UseConcMarkSweepGC Wrapperjava -Xmx100m -XX:+UseG1GC Wrapper 得到的结果是这样的： 12Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread &quot;main&quot; 错误已经被默认的异常处理程序捕获，并且没有任何错误的堆栈信息输出。 以上这些变化可以说明，在资源有限的情况下，你根本无法无法预测你的应用是怎样挂掉的，什么时候会挂掉，所以在开发时，你不能仅仅保证自己的应用程序在特定的环境下正常运行。 解决方案首先是一个毫无诚意的解决方案，如果你仅仅是不想看到java.lang.OutOfMemoryError:GC overhead limit exceeded的错误信息，可以在应用程序启动时添加如下JVM参数： 1-XX:-UseGCOverheadLimit 但是强烈建议不要使用这个选项，因为这样并没有解决任何问题，只是推迟了错误出现的时间，错误信息也变成了我们更熟悉的java.lang.OutOfMemoryError: Java heap space而已。 另一个解决方案，如果你的应用程序确实内存不足，增加堆内存会解决GC overhead limit问题，就如下面这样，给你的应用程序1G的堆内存： 1java -Xmx1024m com.yourcompany.YourClass 但如果你想确保你已经解决了潜在的问题，而不是掩盖java.lang.OutOfMemoryError: GC overhead limit exceeded错误，那么你不应该仅止步于此。你要记得还有profilers和memory dump analyzers这些工具，你需要花费更多的时间和精力来查找问题。还有一点需要注意，这些工具在Java运行时有显著的开销，因此不建议在生产环境中使用。 3、java.lang.OutOfMemoryError:Permgen spaceJava中堆空间是JVM管理的最大一块内存空间，可以在JVM启动时指定堆空间的大小，其中堆被划分成两个不同的区域：新生代（Young）和老年代（Tenured），新生代又被划分为3个区域：Eden、From Survivor、To Survivor java.lang.OutOfMemoryError: PermGen space错误就表明持久代所在区域的内存已被耗尽。 原因分析要理解java.lang.OutOfMemoryError: PermGen space出现的原因，首先需要理解Permanent Generation Space的用处是什么。持久代主要存储的是每个类的信息，比如：类加载器引用、运行时常量池（所有常量、字段引用、方法引用、属性）、字段(Field)数据、方法(Method)数据、方法代码、方法字节码等等。我们可以推断出，PermGen的大小取决于被加载类的数量以及类的大小。 因此，我们可以得出出现java.lang.OutOfMemoryError: PermGen space错误的原因是：太多的类或者太大的类被加载到permanent generation（持久代）。 示例①、最简单的示例正如前面所描述的，PermGen的使用与加载到JVM类的数量有密切关系，下面是一个最简单的示例： 12345678910111213import javassist.ClassPool;public class MicroGenerator &#123; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 100_000_000; i++) &#123; generate(&quot;cn.moondev.User&quot; + i); &#125; &#125; public static Class generate(String name) throws Exception &#123; ClassPool pool = ClassPool.getDefault(); return pool.makeClass(name).toClass(); &#125;&#125; 运行时请设置JVM参数：-XX:MaxPermSize=5m，值越小越好。需要注意的是JDK8已经完全移除持久代空间，取而代之的是元空间（Metaspace），所以示例最好的JDK1.7或者1.6下运行。 代码在运行时不停的生成类并加载到持久代中，直到撑满持久代内存空间，最后抛出java.lang.OutOfMemoryError:Permgen space。代码中类的生成使用了javassist库。 ②、Redeploy-time更复杂和实际的一个例子就是Redeploy（重新部署，你可以想象一下你开发时，点击eclipse的reploy按钮或者使用idea时按ctrl + F5时的过程）。在从服务器卸载应用程序时，当前的classloader以及加载的class在没有实例引用的情况下，持久代的内存空间会被GC清理并回收。如果应用中有类的实例对当前的classloader的引用，那么Permgen区的class将无法被卸载，导致Permgen区的内存一直增加直到出现Permgen space错误。 不幸的是，许多第三方库以及糟糕的资源处理方式（比如：线程、JDBC驱动程序、文件系统句柄）使得卸载以前使用的类加载器变成了一件不可能的事。反过来就意味着在每次重新部署过程中，应用程序所有的类的先前版本将仍然驻留在Permgen区中，你的每次部署都将生成几十甚至几百M的垃圾。 就以线程和JDBC驱动来说说。很多人都会使用线程来处理一下周期性或者耗时较长的任务，这个时候一定要注意线程的生命周期问题，你需要确保线程不能比你的应用程序活得还长。否则，如果应用程序已经被卸载，线程还在继续运行，这个线程通常会维持对应用程序的classloader的引用，造成的结果就不再多说。多说一句，开发者有责任处理好这个问题，特别是如果你是第三方库的提供者的话，一定要提供线程关闭接口来处理清理工作。 让我们想象一个使用JDBC驱动程序连接到关系数据库的示例应用程序。当应用程序部署到服务器上的时：服务器创建一个classloader实例来加载应用所有的类（包含相应的JDBC驱动）。根据JDBC规范，JDBC驱动程序（比如：com.mysql.jdbc.Driver）会在初始化时将自己注册到java.sql.DriverManager中。该注册过程中会将驱动程序的一个实例存储在DriverManager的静态字段内，代码可以参考： 12345678910111213141516171819202122232425// com.mysql.jdbc.Driver源码package com.mysql.jdbc;public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; public Driver() throws SQLException &#123; &#125; static &#123; try &#123; DriverManager.registerDriver(new Driver()); &#125; catch (SQLException var1) &#123; throw new RuntimeException(&quot;Can\\&apos;t register driver!&quot;); &#125; &#125;&#125;// // // // // // // // // //// 再看下DriverManager对应代码private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();public static synchronized void registerDriver(java.sql.Driver driver,DriverAction da) throws SQLException &#123; if(driver != null) &#123; registeredDrivers.addIfAbsent(new DriverInfo(driver, da)); &#125; else &#123; throw new NullPointerException(); &#125;&#125; 现在，当从服务器上卸载应用程序的时候，java.sql.DriverManager仍将持有那个驱动程序的引用，进而持有用于加载应用程序的classloader的一个实例的引用。这个classloader现在仍然引用着应用程序的所有类。如果此程序启动时需要加载2000个类，占用约10MB永久代（PermGen）内存，那么只需要5~10次重新部署，就会将默认大小的永久代（PermGen）塞满，然后就会触发java.lang.OutOfMemoryError: PermGen space错误并崩溃。 解决方案① 解决初始化时的OutOfMemoryError当在应用程序启动期间触发由于PermGen耗尽引起的OutOfMemoryError时，解决方案很简单。 应用程序需要更多的空间来加载所有的类到PermGen区域，所以我们只需要增加它的大小。 为此，请更改应用程序启动配置，并添加（或增加，如果存在）-XX：MaxPermSize参数，类似于以下示例： 1java -XX:MaxPermSize=512m com.yourcompany.YourClass ② 解决Redeploy时的OutOfMemoryError分析dump文件：首先，找出引用在哪里被持有；其次，给你的web应用程序添加一个关闭的hook，或者在应用程序卸载后移除引用。你可以使用如下命令导出dump文件： 1jmap -dump:format=b,file=dump.hprof &lt;process-id&gt; 如果是你自己代码的问题请及时修改，如果是第三方库，请试着搜索一下是否存在”关闭”接口，如果没有给开发者提交一个bug或者issue吧。 ③ 解决运行时OutOfMemoryError首先你需要检查是否允许GC从PermGen卸载类，JVM的标准配置相当保守，只要类一创建，即使已经没有实例引用它们，其仍将保留在内存中，特别是当应用程序需要动态创建大量的类但其生命周期并不长时，允许JVM卸载类对应用大有助益，你可以通过在启动脚本中添加以下配置参数来实现： 1-XX:+CMSClassUnloadingEnabled 默认情况下，这个配置是未启用的，如果你启用它，GC将扫描PermGen区并清理已经不再使用的类。但请注意，这个配置只在UseConcMarkSweepGC的情况下生效，如果你使用其他GC算法，比如：ParallelGC或者Serial GC时，这个配置无效。所以使用以上配置时，请配合： 1-XX:+UseConcMarkSweepGC 如果你已经确保JVM可以卸载类，但是仍然出现内存溢出问题，那么你应该继续分析dump文件，使用以下命令生成dump文件： 1jmap -dump:file=dump.hprof,format=b &lt;process-id&gt; 当你拿到生成的堆转储文件，并利用像Eclipse Memory Analyzer Toolkit这样的工具来寻找应该卸载却没被卸载的类加载器，然后对该类加载器加载的类进行排查，找到可疑对象，分析使用或者生成这些类的代码，查找产生问题的根源并解决它。 4、java.lang.OutOfMemoryError:Metaspace前文已经提过，PermGen区域用于存储类的名称和字段，类的方法，方法的字节码，常量池，JIT优化等，但从Java8开始，Java中的内存模型发生了重大变化：引入了称为Metaspace的新内存区域，而删除了PermGen区域。请注意：不是简单的将PermGen区所存储的内容直接移到Metaspace区，PermGen区中的某些部分，已经移动到了普通堆里面。 原因分析Java8做出如此改变的原因包括但不限于： 应用程序所需要的PermGen区大小很难预测，设置太小会触发PermGen OutOfMemoryError错误，过度设置导致资源浪费。 提升GC性能，在HotSpot中的每个垃圾收集器需要专门的代码来处理存储在PermGen中的类的元数据信息。从PermGen分离类的元数据信息到Metaspace，由于Metaspace的分配具有和Java Heap相同的地址空间，因此Metaspace和Java Heap可以无缝的管理，而且简化了FullGC的过程，以至将来可以并行的对元数据信息进行垃圾收集，而没有GC暂停。 支持进一步优化，比如：G1并发类的卸载，也算为将来做准备吧 正如你所看到的，元空间大小的要求取决于加载的类的数量以及这种类声明的大小。 所以很容易看到java.lang.OutOfMemoryError: Metaspace主要原因：太多的类或太大的类加载到元空间。 示例正如上文中所解释的，元空间的使用与加载到JVM中的类的数量密切相关。 下面的代码是最简单的例子： 12345678910public class Metaspace &#123; static javassist.ClassPool cp = javassist.ClassPool.getDefault(); public static void main(String[] args) throws Exception&#123; for (int i = 0; ; i++) &#123; Class c = cp.makeClass(&quot;eu.plumbr.demo.Generated&quot; + i).toClass(); System.out.println(i); &#125; &#125;&#125; 程序运行中不停的生成新类，所有的这些类的定义将被加载到Metaspace区，直到空间被完全占用并且抛出java.lang.OutOfMemoryError:Metaspace。当使用-XX：MaxMetaspaceSize = 32m启动时，大约加载30000多个类时就会死机。 1234567893102331024Exception in thread &quot;main&quot; javassist.CannotCompileException: by java.lang.OutOfMemoryError: Metaspace at javassist.ClassPool.toClass(ClassPool.java:1170) at javassist.ClassPool.toClass(ClassPool.java:1113) at javassist.ClassPool.toClass(ClassPool.java:1071) at javassist.CtClass.toClass(CtClass.java:1275) at cn.moondev.book.Metaspace.main(Metaspace.java:12) ..... 解决方案第一个解决方案是显而易见的，既然应用程序会耗尽内存中的Metaspace区空间，那么应该增加其大小，更改启动配置增加如下参数： 12// 告诉JVM：Metaspace允许增长到512，然后才能抛出异常-XX：MaxMetaspaceSize = 512m 另一个方法就是删除此参数来完全解除对Metaspace大小的限制（默认是没有限制的）。默认情况下，对于64位服务器端JVM，MetaspaceSize默认大小是21M（初始限制值），一旦达到这个限制值，FullGC将被触发进行类卸载，并且这个限制值将会被重置，新的限制值依赖于Metaspace的剩余容量。如果没有足够空间被释放，这个限制值将会上升，反之亦然。在技术上Metaspace的尺寸可以增长到交换空间，而这个时候本地内存分配将会失败（更具体的分析，可以参考：Java PermGen 去哪里了?）。 你可以通过修改各种启动参数来“快速修复”这些内存溢出错误，但你需要正确区分你是否只是推迟或者隐藏了java.lang.OutOfMemoryError的症状。如果你的应用程序确实存在内存泄漏或者本来就加载了一些不合理的类，那么所有这些配置都只是推迟问题出现的时间而已，实际也不会改善任何东西。 5、java.lang.OutOfMemoryError:Unable to create new native thread一个思考线程的方法是将线程看着是执行任务的工人，如果你只有一个工人，那么他同时只能执行一项任务，但如果你有十几个工人，就可以同时完成你几个任务。就像这些工人都在物理世界，JVM中的线程完成自己的工作也是需要一些空间的 出现java.lang.OutOfMemoryError:Unable to create new native thread就意味着Java应用程序已达到其可以启动线程数量的极限了。 原因分析当JVM向OS请求创建一个新线程时，而OS却无法创建新的native线程时就会抛出Unable to create new native thread错误。一台服务器可以创建的线程数依赖于物理配置和平台，建议运行下文中的示例代码来测试找出这些限制。总体上来说，抛出此错误会经过以下几个阶段： 运行在JVM内的应用程序请求创建一个新的线程 JVM向OS请求创建一个新的native线程 OS尝试创建一个新的native线程，这时需要分配内存给新的线程 OS拒绝分配内存给线程，因为32位Java进程已经耗尽内存地址空间（2-4GB内存地址已被命中）或者OS的虚拟内存已经完全耗尽 Unable to create new native thread错误将被抛出 示例下面的示例不能的创建并启动新的线程。当代码运行时，很快达到OS的线程数限制，并抛出Unable to create new native thread错误。 123456789while(true)&#123; new Thread(new Runnable()&#123; public void run() &#123; try &#123; Thread.sleep(10000000); &#125; catch(InterruptedException e) &#123; &#125; &#125; &#125;).start();&#125; 解决方案有时，你可以通过在OS级别增加线程数限制来绕过这个错误。如果你限制了JVM可在用户空间创建的线程数，那么你可以检查并增加这个限制： 123// macOS 10.12上执行$ ulimit -u709 当你的应用程序产生成千上万的线程，并抛出此异常，表示你的程序已经出现了很严重的编程错误，我不觉得应该通过修改参数来解决这个问题，不管是OS级别的参数还是JVM启动参数。更可取的办法是分析你的应用是否真的需要创建如此多的线程来完成任务？是否可以使用线程池或者说线程池的数量是否合适？是否可以更合理的拆分业务来实现….. 6、java.lang.OutOfMemoryError:Out of swap space?Java应用程序在启动时会指定所需要的内存大小，可以通过-Xmx和其他类似的启动参数来指定。在JVM请求的总内存大于可用物理内存的情况下，操作系统会将内存中的数据交换到磁盘上去。 Out of swap space?表示交换空间也将耗尽，并且由于缺少物理内存和交换空间，再次尝试分配内存也将失败。 原因分析当应用程序向JVM native heap请求分配内存失败并且native heap也即将耗尽时，JVM会抛出Out of swap space错误。该错误消息中包含分配失败的大小（以字节为单位）和请求失败的原因。 Native Heap Memory是JVM内部使用的Memory，这部分的Memory可以通过JDK提供的JNI的方式去访问，这部分Memory效率很高，但是管理需要自己去做，如果没有把握最好不要使用，以防出现内存泄露问题。JVM 使用Native Heap Memory用来优化代码载入（JTI代码生成），临时对象空间申请，以及JVM内部的一些操作。 这个问题往往发生在Java进程已经开始交换的情况下，现代的GC算法已经做得足够好了，当时当面临由于交换引起的延迟问题时，GC暂停的时间往往会让大多数应用程序不能容忍。 java.lang.OutOfMemoryError:Out of swap space?往往是由操作系统级别的问题引起的，例如： 操作系统配置的交换空间不足。 系统上的另一个进程消耗所有内存资源。 还有可能是本地内存泄漏导致应用程序失败，比如：应用程序调用了native code连续分配内存，但却没有被释放。 解决方案解决这个问题有几个办法，通常最简单的方法就是增加交换空间，不同平台实现的方式会有所不同，比如在Linux下可以通过如下命令实现： 123456# 原作者使用，由于我手里并没有Linux环境，所以并未测试# 创建并附加一个大小为640MB的新交换文件swapoff -a dd if=/dev/zero of=swapfile bs=1024 count=655360mkswap swapfileswapon swapfile Java GC会扫描内存中的数据，如果是对交换空间运行垃圾回收算法会使GC暂停的时间增加几个数量级，因此你应该慎重考虑使用上文增加交换空间的方法。 如果你的应用程序部署在JVM需要同其他进程激烈竞争获取资源的物理机上，建议将服务隔离到单独的虚拟机中 但在许多情况下，您唯一真正可行的替代方案是： 升级机器以包含更多内存 优化应用程序以减少其内存占用 当您转向优化路径时，使用内存转储分析程序来检测内存中的大分配是一个好的开始。 7、java.lang.OutOfMemoryError:Requested array size exceeds VM limitJava对应用程序可以分配的最大数组大小有限制。不同平台限制有所不同，但通常在1到21亿个元素之间。 当你遇到Requested array size exceeds VM limit错误时，意味着你的应用程序试图分配大于Java虚拟机可以支持的数组。 原因分析该错误由JVM中的native code抛出。 JVM在为数组分配内存之前，会执行特定于平台的检查：分配的数据结构是否在此平台中是可寻址的。 你很少见到这个错误是因为Java数组的索引是int类型。 Java中的最大正整数为2 ^ 31 - 1 = 2,147,483,647。 并且平台特定的限制可以非常接近这个数字，例如：我的环境上(64位macOS，运行Jdk1.8)可以初始化数组的长度高达2,147,483,645（Integer.MAX_VALUE-2）。如果再将数组的长度增加1到Integer.MAX_VALUE-1会导致熟悉的OutOfMemoryError： 1Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit 但是，在使用OpenJDK 6的32位Linux上，在分配具有大约11亿个元素的数组时，您将遇到Requested array size exceeded VM limit的错误。 要理解你的特定环境的限制，运行下文中描述的小测试程序。 示例12345678for (int i = 3; i &gt;= 0; i--) &#123; try &#123; int[] arr = new int[Integer.MAX_VALUE-i]; System.out.format(&quot;Successfully initialized an array with %,d elements.\\n&quot;, Integer.MAX_VALUE-i); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125;&#125; 该示例重复四次，并在每个回合中初始化一个长原语数组。 该程序尝试初始化的数组的大小在每次迭代时增加1，最终达到Integer.MAX_VALUE。 现在，当使用Hotspot 7在64位Mac OS X上启动代码片段时，应该得到类似于以下内容的输出： 12345678java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Java heap space at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8)java.lang.OutOfMemoryError: Requested array size exceeds VM limit at eu.plumbr.demo.ArraySize.main(ArraySize.java:8) 注意，在出现Requested array size exceeded VM limit之前，出现了更熟悉的java.lang.OutOfMemoryError: Java heap space。 这是因为初始化2 ^ 31-1个元素的数组需要腾出8G的内存空间，大于JVM使用的默认值。 解决方案java.lang.OutOfMemoryError:Requested array size exceeds VM limit可能会在以下任一情况下出现： 数组增长太大，最终大小在平台限制和Integer.MAX_INT之间 你有意分配大于2 ^ 31-1个元素的数组 在第一种情况下，检查你的代码库，看看你是否真的需要这么大的数组。也许你可以减少数组的大小，或者将数组分成更小的数据块，然后分批处理数据。 在第二种情况下，记住Java数组是由int索引的。因此，当在平台中使用标准数据结构时，数组不能超过2 ^ 31-1个元素。事实上，在编译时就会出错：error：integer number too large。 8、Out of memory:Kill process or sacrifice child为了理解这个错误，我们需要补充一点操作系统的基础知识。操作系统是建立在进程的概念之上，这些进程在内核中作业，其中有一个非常特殊的进程，名叫“内存杀手（Out of memory killer）”。当内核检测到系统内存不足时，OOM killer被激活，然后选择一个进程杀掉。哪一个进程这么倒霉呢？选择的算法和想法都很朴实：谁占用内存最多，谁就被干掉。如果你对OOM Killer感兴趣的话，建议你阅读参考资料2中的文章。 当可用虚拟虚拟内存(包括交换空间)消耗到让整个操作系统面临风险时，就会产生Out of memory:Kill process or sacrifice child错误。在这种情况下，OOM Killer会选择“流氓进程”并杀死它。 原因分析默认情况下，Linux内核允许进程请求比系统中可用内存更多的内存，但大多数进程实际上并没有使用完他们所分配的内存。这就跟现实生活中的宽带运营商类似，他们向所有消费者出售一个100M的带宽，远远超过用户实际使用的带宽，一个10G的链路可以非常轻松的服务100个(10G/100M)用户，但实际上宽带运行商往往会把10G链路用于服务150人或者更多，以便让链路的利用率更高，毕竟空闲在那儿也没什么意义。 Linux内核采用的机制跟宽带运营商差不多，一般情况下都没有问题，但当大多数应用程序都消耗完自己的内存时，麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。就如同上面的例子中，如果150人都占用100M的带宽，那么总的带宽肯定超过了10G这条链路能承受的范围。 示例当你在Linux上运行如下代码： 12345678910public static void main(String[] args)&#123; List&lt;int[]&gt; l = new java.util.ArrayList(); for (int i = 10000; i &lt; 100000; i++) &#123; try &#123; l.add(new int[100000000]); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125;&#125; 在Linux的系统日志中/var/log/kern.log会出现以下日志： 12Jun 4 07:41:59 plumbr kernel: [70667120.897649] Out of memory: Kill process 29957 (java) score 366 or sacrifice childJun 4 07:41:59 plumbr kernel: [70667120.897701] Killed process 29957 (java) total-vm:2532680kB, anon-rss:1416508kB, file-rss:0kB 注意：你可能需要调整交换文件和堆大小，否则你将很快见到熟悉的Java heap space异常。在原作者的测试用例中，使用-Xmx2g指定的2g堆，并具有以下交换配置： 12345# 注意：原作者使用，由于我手里并没有Linux环境，所以并未测试swapoff -a dd if=/dev/zero of=swapfile bs=1024 count=655360mkswap swapfileswapon swapfile 解决方案解决这个问题最有效也是最直接的方法就是升级内存，其他方法诸如：调整OOM Killer配置、水平扩展应用，将内存的负载分摊到若干小实例上….. 我们不建议的做法是增加交换空间，具体原因已经在前文说过。参考资料②中详细的介绍了怎样微调OOM Killer配置以及OOM Killer选择进程算法的实现，建议你参考阅读。 参考资料：① 想要了解更多PermGen与Metaspace的内容推荐你阅读： Java 8会解决PermGen OutOfMemoryError问题吗? Java PermGen 去哪里了? ② 如果你对OOM Killer感兴趣的话，强烈建议你阅读这篇文章： 理解和配置 Linux 下的 OOM Killer","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"React Virtual DOM","date":"2018-10-06T16:28:21.000Z","path":"wiki/前端/React Vitual DOM/","text":"为什么说操作DOM慢DOM对象本身是一个js对象，其实操作这个对象并不慢，慢的是操作这个对象后，会触发一些浏览器行为，比如布局(layout)和绘制(paint)。 浏览器渲染主要流程浏览器如何工作的 浏览器对HTMl的渲染分为5个步骤： 处理HTML标记并构建出DOM树 处理CSS标记并构建CSSOM树 将两者关联生成Render Tree Layout根据Render Tree来布局，计算每个节点的几何信息 根据计算好的信息绘制整个页面 其中，layout是最耗时的步骤。因此需要最小化layout的次数 什么情况下浏览器会进行layoutlayout用来计算文档中元素的位置和大小，在HTML第一次被加载的时候，会有一次layout，称为reflow/如下操作也会触发reflow 插入、删除、移动、更新DOM 改变页面内容，如输入框的文本 改变CSS样式 改变窗口大小 Vitual DOM更快么Virtual DOM并不比直接操作DOM快，只不过使用Vitual DOM可以减少不必要的DOM更新，从而减少比较耗时的layout和paint工作。","tags":[{"name":"React","slug":"React","permalink":"http://polyval.github.io/Wiki/tags/React/"}],"categories":[{"name":"前端","slug":"前端","permalink":"http://polyval.github.io/Wiki/categories/前端/"}]},{"title":"性能瓶颈","date":"2018-10-06T16:28:21.000Z","path":"wiki/Java/性能瓶颈/","text":"一个好的程序，应该是能够充分利用CPU。如果一个程序在单CPU的机器上无论在多大的压力下都无法令CPU的使用率接近100% ,说明这个程序设计地有问题。 常见的性能瓶颈不恰当的同步导致的资源占用 锁加得不恰当 锁粒度过大 不恰当的线程模型 效率低下的SQL或者不恰当的数据库设计不恰当的GC参数线程数量不足内存泄露导致的频繁GC通过线程堆栈识别性能瓶颈典型的堆栈特征 绝大多数线程的堆栈表现在同一个调用上下文上，且只剩下非常少的空闲线程 绝大多数线程处于等待状态，只有几个工作的线程，总体性能上不去。可能的原因是，系统存在关键路径，在该关键路径上没有足够的能力给下个阶段输送大量的任务，导致其 它地方空闲。如在消息分发系统，消息分发一般是一个线程，而消息处理是多个线程，这 时候消息分发是瓶颈的话，那么从线程堆栈就会观察到上面提到的现象:即该关键路径 没有足够的能力给下个阶段输送大量的任务，导致其它地方空闲 线程总的数量很少。这个一般与线程池的设计有关。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"操作系统是如何实现虚拟内存的","date":"2018-10-06T16:28:21.000Z","path":"wiki/操作系统/操作系统是如何实现虚拟内存的/","text":"要明白操作系统是如何实现虚拟内存的，首先应该明白操作系统为什么要需要虚拟内存 为什么需要虚拟内存早期的程序中访问的内存地址都是实际的物理内存地址。 程序需要加载在内存上运行，即形成进程。起初，只有一个进程信息可以被加载到内存，需要运行另一个进程时，需要将当前进程的信息先存储到磁盘上，然后从磁盘上读取另一个进程的信息。但是磁盘I/O是很慢的，导致任务切换的效率很低 。因此，人们希望将多个进程可以共同存放在内存上，这就出现了一个问题：如何避免一个进程读取、篡改另一个进程的内存信息，即对进程间实现隔离和保护。 同时，程序在编写时，其访问数据和指令跳转时的目标地址很多是固定的。但是程序在加载在内存时，不可能说每次我们都能够分配固定地址的内存给它。尤其是在我们想运行同一程序的多个实例的时候，由于同一程序使用的物理地址是一样的，一起运行就会有冲突。 另外，程序使用的内存会被物理内存所限制，即程序使用的内存不能超过物理内存。 内存虚拟化就是为了解决这些问题出现的，它将程序给的地址看作是虚拟地址(Virtual Address)，然后通过将虚拟地址转换为实际的物理地址，通过操作系统对这个转化过程的控制，来实现隔离、保护、和易用。 如何实现虚拟内存我们可以把我们为什么需要虚拟内存抽象成虚拟内存要实现的几个目标。 虚拟内存的几个目标 不可见性 即对于程序来说，并不知道内存被虚拟化了，程序认为自己拥有独自的物理内存 高效率 虚拟内存的效率要高,不能让程序运行变得太慢(时间效率),也不能因为实现虚拟内存占用太大空间(空间效率)。为了保证时间效率，需要用到硬件的支持。 保护 操作系统需要保证进程间相互隔离，同时也要将操作系统与进程隔离开来。 实现虚拟内存的关键技术是：地址转化，实现地址转化的硬件称为内存管理单元MMU(Memory Management Unit)。我们先来看看地址转化最初的原型：base and bounds，也叫动态重定位(dynamic relocation)。 动态重定位在动态重定位方法中，每个CPU需要两个寄存器来帮助它实现地址转化：base register 和 bounds register。 程序在编写和编译时，其使用的内存地址从0开始。当程序运行时，如OS打算在32KB处开始载入程序，则OS将base寄存器的值设为32KB。程序的地址转化成：$$实际物理地址 = 虚拟地址 + base$$因此，base寄存器实现了地址转化的作用，而bounds寄存器的作用则是进行保护，限制地址引用的范围。 当进行进程间切换时，需要保存base-bounds寄存器的值，以便恢复进程。这个值保存在进程控制块PCB(process control block)里。 动态重定位的缺点动态重定位的缺点在于它会造成内部碎片(internal fragmentation)，造成内存的浪费。如图所示，由于进程的堆和栈不是很大，其中的内存就被浪费掉了 。 为了解决内部碎片的问题，出现了分段技术。 分段(Segmentation)分段技术的出现是为了解决程序因占用连续的内存空间而产生内部碎片的问题，利用分段解决内部碎片问题的思想很简单：将进程的内存空间按照逻辑进行分段，每段可存放在物理内存的不同位置，在动态重定位一对base-bounds寄存器的基础上，给进程的每段都分配一对base-bounds寄存器。常见分段方式分为三段：代码段、栈和堆。比如说我们要对某个代码段的虚拟地址进行寻址，只需要根据代码段的base-bounds寄存器，按照动态重定位的方式寻址即可。那么，给定一个虚拟地址，如何判断它是属于哪个段的呢？ 如何确定虚拟地址属于哪个段有两种方法进行确定。 将地址前面几位当作段标志比如一个14位的虚拟内存，我们可以将其前两位当做段的标志位，如00表示代码段，01表示堆，11表示栈。 根据虚拟地址如何产生的来判断如果虚拟地址由程序计数器(program count)产生的，则为代码段，如果为栈指针，则为栈段，否则为堆段。 MMU记录的其它信息除了每段的base-bounds寄存器外，MMU还记录了段的其它一些信息。 因为栈是反方向扩张的，因此需要记录内存扩张的方向。Protection用来表示段的属性，可以用来共享一些段。 分段的缺点每个程序都不一样，其各段所占用的内存空间大小也不一样，造成内存的占用情况如下图所示 内存上出现了各种大小的小洞，如果我们需要分配一个新段，比这个新段大小小的内存空间对于我们来说都是没有用的，这就造成了内存的浪费，这种浪费称为外部碎片(external fragmentation)。为了解决这个问题，出现了各种方法，如内存整理(compact)，各种内存管理算法(best fit、first fit)。但是并没有完美的方法解决这个问题。 分页(Paging)分段中引起外部碎片的原因是每段的大小都不一样。分页对内存的处理方式是:将虚拟内存和物理内存分为若干个固定长度的单元，这个单元称为页。 如何寻址每个进程都对应一个页表(page table)，页表存储着虚拟内存页对应的实际物理内存页。虚拟地址需要分为两部分：虚拟页号VPN(virtual page number)和偏移量offset。通过页表可以知道VPN对应的PFN，通过offset进行准确寻址。 页表存放在哪页表占用空间很大。举个例子，假设一个32位的地址空间，每页大小为4KB，则虚拟内存分为20位的VPN和12位的偏移量(10位1KB，4KB则为12位)。20位的VPN表示存在$2^{20}$条转化映射，假设每条映射占用4字节，则一个页表需要占用4M的大小。 由于页表太大，因此将内部存储在内存中。在MMU中的页表基(page-table base)寄存器中存放页表在内存中的起始位置。 分页的缺点因为页表存放在内存上，在对虚拟地址进行转化时，首先需要从内存中的页表读到其对应物理页，相当于多了一次内存的读操作，因此分页会降低速度，同时页表的存储占用过多内存。 给分页加加速要想加加速，就需要硬件来帮个忙。TLB (Translation-Lookaside Buffer)，中文译为快表。TLB是集成在MMU上的缓存，用来存储部分页表记录。 查询页表时，首先去TLB查，查到了称为TLB命中(hit)，如果没查到，称为TLB失败(miss)，此时去内存中的页表查。缓存大小有限，当有新记录放入到TLB，需要进行缓存置换，缓存置换有许多方法，这里不再展开。","tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://polyval.github.io/Wiki/tags/操作系统/"}],"categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://polyval.github.io/Wiki/categories/操作系统/"}]},{"title":"线程状态","date":"2018-10-06T16:28:21.000Z","path":"wiki/Java/线程状态/","text":"线程的状态转换关系 1）BLOCKED：线程等待监视器锁，就是线程在等待获取锁进入同步块或者同步方法中。两个死锁的线程即是Blocked。 2）WAITING： 三种方法可以使线程进入WAITING: Object.wait with no timeout Thread.join with no timeout LockSupport.park 比BLOCKED状态进步一些，指我已经获得锁了，但由于有些条件不满足，我自己等会，调用object.wait()方法。等条件满足了，别的线程调用notify再叫我。另外也可以调用Thread.join()方法，顾名思义就是调用别的线程的join方法，让别人join进来先执行，那我就只能等会了。但是由于wait()和notify()以及notifyAll()用于协调对共享资源的存取，所以必须在synchronized块中使用，即调用wait的时候需要获取锁，调用后锁释放。所以即便wait状态的线程被notfiy唤醒了，也需要再次获得锁，所以唤醒后进入Blocked状态。 3）TIMED_WAITING： 如下方法使线程进入该状态 Thread.sleep Object.wait with timeout Thread.join with timeout LockSupport.parkNanos LockSupport.parkUntil 类比WAITING，差异是不需要notify()或者notifyAlL()方法唤醒，时间到了我自己醒了。另外sleep比较好理解，就是让当前线程睡一会，与wait的区别是它不释放锁。 4）RUNNABLE不用多说，在JAVA虚拟机中已经在运行，但是有可能在等待操作系统资源，比如CPU时间片。 处于Runnable的线程一定消耗cpu么 不一定，比如线程处于io等待，实际上是线程是挂起，不消耗cpu的。 Java线程堆栈解读 tid和nid在采集Java线程堆栈时，有个nid和tid。tid表示Java层面的线程id，是Java给每个线程所分配的一个id，nid(Native thread ID)表示的本地线程id，与实际的操作系统线程id相一致。 堆栈中与锁相关的三种状态 当一个线程占有一个锁的时候，线程堆栈中会打印—locked 当一个线程正在等待其它线程释放该锁，线程堆栈中会打印—waiting to lock 当一个线程占有一个锁，但又执行到该锁的wait()上，线程堆栈中首先打印locked,然后又 会打印—waiting on","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"什么是Java内存模型","date":"2018-10-06T16:28:21.000Z","path":"wiki/Java/什么是Java内存模型/","text":"什么是Java内存模型Java内存模型定义了Java虚拟机与计算机内存的工作方式。Java虚拟机是计算机的模型，这个计算机模型自然包括了内存模型，即Java内存模型。 Java内存模型描述了Java线程与内存的交互方式，它屏蔽了各种硬件和操作系统的访问差异，保证了Java程序在各平台下对内存的访问都能保持效果一致。解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。 Java内存模型规定了 所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。 Java内存模型定义了Java线程与内存的交互方式，在Java语言层面，提供了volatile、synchronized、final等关键字来描述程序多线程行为，而Java内存模型则定义了这些关键字的行为。 支撑Java内存模型的基本原理指令重排序在执行程序时，为了提高性能，编译器和处理器会对指令做重排序。但是，JMM确保在不同的编译器和不同的处理器平台之上，通过插入特定类型的Memory Barrier来禁止特定类型的编译器重排序和处理器重排序，为上层提供一致的内存可见性保证。 Happens-Before原则先抛一个问题：当一个多线程共享变量被某个线程修改后，如何让这个修改被需要读取这个变量的线程感知到。 JMM定义了Happens-Before原则。只要我们理解了Happens-Before原则，无需了解JVM底层的内存操作，就可以利用Happens-Before原则来解决并发编程中的变量可见性问题，也可以理解什么时候变量对其他线程是可见的。 JMM定义的Happens-Before原则是一组偏序关系：对于两个操作A和B，这两个操作可以在不同的线程中执行。如果A Happens-Before B，那么可以保证，当A操作执行完后，A操作的执行结果对B操作是可见的。 Happens-Before的规则包括： 程序顺序规则 锁定规则 volatile变量规则 线程启动规则 线程结束规则 中断规则 终结器规则 传递性规则 下面我们将详细讲述这8条规则的具体内容。 程序顺序规则在一个线程内部，按照程序代码的书写顺序，书写在前面的代码操作Happens-Before书写在后面的代码操作。这时因为Java语言规范要求JVM在单个线程内部要维护类似严格串行的语义，如果多个操作之间有先后依赖关系，则不允许对这些操作进行重排序。 锁定规则对锁M解锁之前的所有操作Happens-Before对锁M加锁之后的所有操作。 1234567891011class HappensBeforeLock &#123; private int value = 0; public synchronized void setValue(int value) &#123; this.value = value; &#125; public synchronized int getValue() &#123; return value; &#125;&#125; 上面这段代码，setValue和getValue两个方法共享同一个监视器锁。假设setValue方法在线程A中执行，getValue方法在线程B中执行。setValue方法会先对value变量赋值，然后释放锁。getValue方法会先获取到同一个锁后，再读取value的值。所以根据锁定原则，线程A中对value变量的修改，可以被线程B感知到。如果这个两个方法上没有synchronized声明，则在线程A中执行setValue方法对value赋值后，线程B中getValue方法返回的value值并不能保证是最新值。本条锁定规则对显示锁(ReentrantLock)和内置锁(synchronized)在加锁和解锁等操作上有着相同的内存语义。对于锁定原则，可以像下面这样去理解：同一时刻只能有一个线程执行锁中的操作，所以锁中的操作被重排序外界是不关心的，只要最终结果能被外界感知到就好。除了重排序，剩下影响变量可见性的就是CPU缓存了。在锁被释放时，A线程会把释放锁之前所有的操作结果同步到主内存中，而在获取锁时，B线程会使自己CPU的缓存失效，重新从主内存中读取变量的值。这样，A线程中的操作结果就会被B线程感知到了。 volatile变量规则对一个volatile变量的写操作及这个写操作之前的所有操作Happens-Before对这个变量的读操作及这个读操作之后的所有操作。 123456789101112131415161718Map configOptions;char[] configText; //线程间共享变量，用于保存配置信息// 此变量必须定义为volatilevolatile boolean initialized = false;// 假设以下代码在线程A中执行// 模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;// 假设以下代码在线程B中执行// 等待initialized为true，代表线程A已经把配置信息初始化完成while (!initialized) &#123; sleep();&#125;//使用线程A中初始化好的配置信息doSomethingWithConfig(); 上面这段代码，读取配置文件的操作和使用配置信息的操作分别在两个不同的线程A、B中执行，两个线程通过共享变量configOptions传递配置信息，并通过共享变量initialized作为初始化是否完成的通知。initialized变量被声明为volatile类型的，根据volatile变量规则，volatile变量的写入操作Happens-Before对这个变量的读操作，所以在线程A中将变量initialized设为true，线程B中是可以感知到这个修改操作的。但是更牛逼的是，volatile变量不仅可以保证自己的变量可见性，还能保证书写在volatile变量写操作之前的操作对其它线程的可见性。考虑这样一种情况，如果volatile变量仅能保证自己的变量可见性，那么当线程B感知到initialized已经变成true然后执行doSomethingWithConfig操作时，可能无法获取到configOptions最新值而导致操作结果错误。所以volatile变量不仅可以保证自己的变量可见性，还能保证书写在volatile变量写操作之前的操作Happens-Before书写在volatile变量读操作之后的那些操作。可以这样理解volatile变量的写入和读取操作流程：首先，volatile变量的操作会禁止与其它普通变量的操作进行重排序，例如上面代码中会禁止initialized = true与它上面的两行代码进行重排序(但是它上面的代码之间是可以重排序的)，否则会导致程序结果错误。volatile变量的写操作就像是一条基准线，到达这条线之后，不管之前的代码有没有重排序，反正到达这条线之后，前面的操作都已完成并生成好结果。然后，在volatile变量写操作发生后，A线程会把volatile变量本身和书写在它之前的那些操作的执行结果一起同步到主内存中。最后，当B线程读取volatile变量时，B线程会使自己的CPU缓存失效，重新从主内存读取所需变量的值，这样无论是volatile本身，还是书写在volatile变量写操作之前的那些操作结果，都能让B线程感知到，也就是上面程序中的initialized和configOptions变量的最新值都可以让线程B感知到。原子变量与volatile变量在读操作和写操作上有着相同的语义。 线程启动规则Thread对象的start方法及书写在start方法前面的代码操作Happens-Before此线程的每一个动作。start方法和新线程中的动作一定是在两个不同的线程中执行。线程启动规则可以这样去理解：调用start方法时，会将start方法之前所有操作的结果同步到主内存中，新线程创建好后，需要从主内存获取数据。这样在start方法调用之前的所有操作结果对于新创建的线程都是可见的。 线程终止规则线程中的任何操作都Happens-Before其它线程检测到该线程已经结束。这个说法有些抽象，下面举例子对其进行说明。假设两个线程s、t。在线程s中调用t.join()方法。则线程s会被挂起，等待t线程运行结束才能恢复执行。当t.join()成功返回时，s线程就知道t线程已经结束了。所以根据本条原则，在t线程中对共享变量的修改，对s线程都是可见的。类似的还有Thread.isAlive方法也可以检测到一个线程是否结束。可以猜测，当一个线程结束时，会把自己所有操作的结果都同步到主内存。而任何其它线程当发现这个线程已经执行结束了，就会从主内存中重新刷新最新的变量值。所以结束的线程A对共享变量的修改，对于其它检测了A线程是否结束的线程是可见的。 中断规则一个线程在另一个线程上调用interrupt,Happens-Before被中断线程检测到interrupt被调用。假设两个线程A和B，A先做了一些操作operationA，然后调用B线程的interrupt方法。当B线程感知到自己的中断标识被设置时(通过抛出InterruptedException，或调用interrupted和isInterrupted),operationA中的操作结果对B都是可见的。 终结器规则一个对象的构造函数执行结束Happens-Before它的finalize()方法的开始。“结束”和“开始”表明在时间上，一个对象的构造函数必须在它的finalize()方法调用时执行完。根据这条原则，可以确保在对象的finalize方法执行时，该对象的所有field字段值都是可见的。 传递性规则如果操作A Happens-Before B，B Happens-Before C，那么可以得出操作A Happens-Before C。","tags":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"http://polyval.github.io/Wiki/categories/Java/"}]},{"title":"什么是微服务","date":"2018-04-19T16:28:21.000Z","path":"wiki/微服务/什么是微服务/","text":"什么是微服务微服务，又称微服务架构。是一种新兴的软件架构模式。微服务架构模式通过将多种细小的服务进行整合来形成软件，这些服务运行在自己独立的进程上，服务之间通过轻量级机制(常用的是HTTP API)进行通讯。 微服务架构与传统架构的区别传统软件架构模式是一体化架构(Monolithic Architecture)，一体化架构是指软件最终以一个整体的形态呈现出来，是一个单一的可执行程序，改变其中任何一个部分都需要重新生成和部署这个软件。而在微服务架构，服务就是一个运行的程序，运行在独立的进程上，如果你改变了某个服务涉及的代码，只需要重新部署这个服务即可。 微服务的优点 易于扩展 一体化应用进行扩展时需要针对整个应用进行扩展 ，而微服务架构可以根据服务进行扩展 便于持续交付 改变其中某个部分只需要重新生成和部署对应的服务 服务可重用 容错性更强 通过功能分散，使得应用不会轻易因为一个错误而崩溃 微服务的缺点 远程调用会有更多的延时 测试更麻烦","tags":[{"name":"微服务","slug":"微服务","permalink":"http://polyval.github.io/Wiki/tags/微服务/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"http://polyval.github.io/Wiki/categories/微服务/"}]},{"title":"云计算","date":"2017-02-19T16:28:21.000Z","path":"wiki/云计算/云计算/","text":"什么是云计算云计算是通过网络以自助服务的方式获得所需要的IT资源的模式。 获取路径：通过网络 获取方式：自助服务 获取对象：IT资源(如计算能力、存储能力、带宽等) 横向伸缩通过增加或减少相同IT资源个数来实现伸缩 纵向伸缩通过用具有更高或者更低资源能力的IT资源进行替换来实现伸缩 云计算的三种服务模式 IaaS：基础设施服务，Infrastructure-as-a-service PaaS：平台服务，Platform-as-a-service SaaS：软件服务，Software-as-a-service","tags":[{"name":"云计算","slug":"云计算","permalink":"http://polyval.github.io/Wiki/tags/云计算/"}],"categories":[{"name":"云计算","slug":"云计算","permalink":"http://polyval.github.io/Wiki/categories/云计算/"}]}]}